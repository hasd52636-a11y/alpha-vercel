> ## Documentation Index
> Fetch the complete documentation index at: https://docs.bigmodel.cn/llms.txt
> Use this file to discover all available pages before exploring further.

# 模型概览

<Tip>
  GLM Coding 套餐全新上线！旗舰模型 GLM-4.7 包月畅享，适用于 Claude Code、Cline 等主流编程工具，1/7价格，3倍用量，独家升级支持联网搜索&多模态理解。限时特惠 ¥20/月起，手慢无，[立享好价](https://zhipuaishengchan.datasink.sensorsdata.cn/t/Pd)！
</Tip>

## 推荐模型

<CardGroup cols={3}>
  <Card title="GLM-4.7" icon={<svg style={{maskImage: "url(/resource/icon/book-open.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="/cn/guide/models/text/glm-4.7">
    **最新旗舰基座模型**

    * 开源 SOTA 能力
    * Agentic Coding 体验更优
  </Card>

  <Card title="GLM-4.6V" icon={<svg style={{maskImage: "url(/resource/icon/glasses.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="/cn/guide/models/vlm/glm-4.6v">
    **旗舰视觉推理模型**

    * 全面支持工具调用
    * 128K超长上下文
  </Card>

  <Card title="GLM-Image" icon={<svg style={{maskImage: "url(/resource/icon/image.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="/cn/guide/models/image-generation/glm-image">
    **旗舰图像生成模型**

    * 文字渲染开源SOTA
    * 支持多分辨率
  </Card>
</CardGroup>

## 模型一览

<Tip>
  若需要看模型价格，请直接前往[价格页面](https://open.bigmodel.cn/pricing)。
</Tip>

### 文本模型

文本模型是一类专注于处理和生成自然语言的模型，涵盖了语言理解与推理能力，能够自动处理海量文本数据并进行逻辑推导。智谱的文本模型结合了强大的语言模型和推理模型，使得系统不仅能理解和生成文本内容，还能进行高层次的推理和判断。

| 模型                                                          | 定位       | 特点                                                            | 上下文  | 最大输出 |
| :---------------------------------------------------------- | :------- | :------------------------------------------------------------ | :--- | :--- |
| [GLM-4.7](/cn/guide/models/text/glm-4.7)                    | 高智能旗舰    | - 通用对话、推理与智能体能力上实现全面升级<br />- 编程更强、更稳、审美更好                    | 200K | 128K |
| [GLM-4.7-FlashX](/cn/guide/models/text/glm-4.7)             | 轻量高速     | - 小尺寸，强能力<br />- 适用于中文写作、翻译、长文本、情感/角色扮演等通用场景                  | 200K | 128K |
| [GLM-4.6](/cn/guide/models/text/glm-4.6)                    | 超强性能     | - 上下文提升至200K <br />- 高级编码能力、强大推理以及工具调用能力                      | 200K | 128K |
| [GLM-4.5-Air](/cn/guide/models/text/glm-4.5)                | 高性价比     | - 在推理、编码和智能体任务上表现强劲                                           | 128K | 96K  |
| [GLM-4.5-AirX](/cn/guide/models/text/glm-4.5)               | 高性价比-极速版 | - 推理速度快，且价格适中 <br />- 适用于时效性有较强要求的场景                          | 128K | 96K  |
| [GLM-4-Long](/cn/guide/models/text/glm-4-long)              | 超长输入     | - 支持高达 1M 的上下文长度 <br />- 能够理解和回应复杂的查询 <br />- 为处理超长文本和记忆型任务设计 | 1M   | 4K   |
| [GLM-4-FlashX-250414](/cn/guide/models/text/glm-4)          | 高速低价     | - Flash 增强版本 <br />- 超快推理速度 <br />- 更高并发保障                    | 128K | 16K  |
| [GLM-4.7-Flash](/cn/guide/models/free/glm-4.7-flash)        | 免费模型     | - 最新基座模型的普惠版本                                                 | 200K | 128K |
| [GLM-4.5-Flash](/cn/guide/models/free/glm-4.5-flash) （即将下线） | 免费模型     | - 支持深度思考模式<br />- 支持最长 128K 的上下文处理                            | 128K | 96K  |
| [GLM-4-Flash-250414](/cn/guide/models/text/glm-4)           | 免费模型     | - 超长上下文处理能力 <br />- 多语言支持 <br />- 支持外部工具调用                    | 128K | 16K  |

### 视觉模型

视觉模型是一类能处理图像或视频等视觉信息的模型，广泛应用于识别、分析与决策任务。其中，视觉理解模型侧重于看懂图像内容，如识别物体、场景和关系；而视觉推理模型进一步具备看图思考的能力，能结合视觉与语言信息完成逻辑判断、因果分析和多步推理，常用于图文问答、图像描述生成、多模态对齐等复杂任务。

| 模型                                                                       | 定位       | 特点                                                             | 上下文                                                         | 最大输出 |
| :----------------------------------------------------------------------- | :------- | :------------------------------------------------------------- | :---------------------------------------------------------- | :--- |
| [GLM-4.6V](/cn/guide/models/vlm/glm-4.6v)                                | 旗舰视觉推理   | - 视觉推理模型SOTA <br />- 原生支持工具调用 <br />- 超长上下文 <br />- 前端代码复刻效果提升 | 128K                                                        | 32K  |
| [GLM-OCR](/cn/guide/models/vlm/glm-ocr)                                  | 轻量图文解析   | - 性能SOTA <br />- 高精度、高效率 <br />- 支持多种常见复杂文档解析                  | 输入: <br /> - 单图 ≤ 10 MB，PDF ≤ 50 MB <br /> - 最大支持100页<br /> | /    |
| [AutoGLM-Phone](/cn/guide/models/vlm/autoglm-phone)                      | 手机智能助理框架 | - 支持用自然语言自动完成 App 操作任务 <br />- 支持完整操作指令集                       | 20K                                                         | 2048 |
| [GLM-4.1V-Thinking-FlashX](/cn/guide/models/vlm/glm-4.1v-thinking)       | 轻量视觉推理   | - 视觉推理能力 <br />- 复杂场景理解 <br />- 多步骤分析<br />- 高并发               | 64K                                                         | 16K  |
| [GLM-4.6V-Flash](/cn/guide/models/free/glm-4.6v-flash)                   | 免费模型     | - 视觉推理能力 <br />- 支持工具调用 <br />- 可灵活开关思考模式                      | 128K                                                        | 32K  |
| [GLM-4.1V-Thinking-Flash](/cn/guide/models/free/glm-4.1v-thinking-flash) | 免费模型     | - 视觉推理能力 <br />- 复杂场景理解 <br />- 多步骤分析                          | 64K                                                         | 16K  |
| [GLM-4V-Flash](/cn/guide/models/free/glm-4v-flash)                       | 免费模型     | - 图像理解 <br />- 多语言支持                                           | 16K                                                         | 1K   |

### 图像生成模型

图像生成模型是一类通过学习海量图像数据，实现从文本生成高质量图片的模型，广泛应用于视觉内容创作、游戏美术、产品设计、医学影像合成等领域。

| 模型                                                       | 定位     | 特点                                            | 多分辨率 |
| :------------------------------------------------------- | :----- | :-------------------------------------------- | :--- |
| [GLM-Image](/cn/guide/models/image-generation/glm-image) | 旗舰图像生成 | - 在复杂指令遵循与知识密集场景上更强<br />- 文字渲染开源 SOTA，汉字尤其出色 | 支持   |
| [CogView-4](/cn/guide/models/image-generation/cogview-4) | 图像生成   | - 高质量图像生成 <br />- 风格多样化 <br />- 细节丰富          | 支持   |
| [CogView-3-Flash](/cn/guide/models/free/cogview-3-flash) | 免费模型   | - 创意丰富多样 <br />- 推理速度快                        | 支持   |

### 视频生成模型

视频生成模型是一类通过学习时序视觉数据，从文本、图像或其他视频素材生成动态视频内容的模型，广泛应用于影视制作、虚拟人、动画生成、数字营销等领域。

| 模型                                                           | 定位    | 特点                                                                      | 多模态支持     | 多分辨率 |
| :----------------------------------------------------------- | :---- | :---------------------------------------------------------------------- | --------- | :--- |
| [CogVideoX-3](/cn/guide/models/video-generation/cogvideox-3) | 高智能旗舰 | - 主观清晰度大幅提升<br />- 更好的指令遵循、物理真实模拟<br />- 现实、3D风格场景表现提升<br />- 新增首尾帧生成功能 | 图像、文本、首尾帧 | 支持   |
| [Vidu Q1](/cn/guide/models/video-generation/viduq1)          | 质量较优  | - 影视级的画质清晰度 <br />- 精准解决画面崩坏 <br />- 多艺术形态的风格 <br />- 行业标杆级转场流畅度        | 图像、文本、首尾帧 | 不支持  |
| [Vidu 2](/cn/guide/models/video-generation/vidu2)            | 高速低价  | - 速度优、性价比优 <br />- 语义增强的首尾帧衔接 <br />- 多参考图的一致性强化                        | 图像、参考、首尾帧 | 不支持  |
| [CogVideoX-Flash](/cn/guide/models/free/cogvideox-flash)     | 免费模型  | - 沉浸式AI音效 <br />- 4K 高清画质呈现 <br />- 10 秒视频时长拓展 <br />- 60fps 高帧率输出      | 图像、文本     | 支持   |

### 音视频模型

音视频模型是一类处理音频与视频信号的多模态模型，能够理解、生成或编辑视听内容，广泛应用于虚拟人、语音驱动动画、视频配音与剪辑、跨模态检索等场景。

| 模型                                                              | 定位     | 特点                                                          | 多模态支持    |
| :-------------------------------------------------------------- | :----- | :---------------------------------------------------------- | :------- |
| [GLM-TTS](/cn/guide/models/sound-and-video/glm-tts)             | 语音合成模型 | - 超拟人语音合成，情感表达增强 <br />- 非流式与流式接口                           | 文本       |
| [GLM-TTS-Clone](/cn/guide/models/sound-and-video/glm-tts-clone) | 音色克隆模型 | - 3秒音频即可生成音色 <br />- 支持普通话及轻口音<br />- 细腻的情感表达               | 文本、音频    |
| [GLM-ASR-2512](/cn/guide/models/sound-and-video/glm-asr-2512)   | 语音识别   | - 字符错误率（CER）仅为 0.0717 <br />- 支持用户自定义词汇 <br />- 支持多种主流语言和方言 | 音频       |
| [GLM-Realtime](/cn/guide/models/sound-and-video/glm-realtime)   | 实时音视频  | - 能够提供实时的视频通话功能，通话记忆时长长达2分钟 <br />- 具有跨文本、音频和视频进行实时推理的能力    | 视频、音频、文本 |
| [GLM-4-Voice](/cn/guide/models/sound-and-video/glm-4-voice)     | 语音模型   | - 直接理解和生成中英文语音，实现实时语音对话 <br />- 根据用户指令灵活调整语音的情感、语调、语速和方言等特性 | 文本、音频    |

### 向量模型

向量模型用于将高维的离散数据转换为低维的连续向量，捕捉数据的语义特征和关系。您可以使用我们的向量模型构建语义检索增强、聚类、主题建模和分类等功能。

| 模型                                                    | 定位 | 上下文 |
| :---------------------------------------------------- | :- | :-- |
| [Embedding-3](/cn/guide/models/embedding/embedding-3) | V3 | 8K  |
| [Embedding-2](/cn/guide/models/embedding/embedding-2) | V2 | 8K  |

### 其他模型

| 模型         | 定位    | 特点                               | 上下文  | 最大输出 |
| :--------- | ----- | :------------------------------- | :--- | :--- |
| CharGLM-4  | 拟人模型  | 适用于情感陪伴和虚拟角色                     | 8K   | 4K   |
| Emohaa     | 心理模型  | 具备专业咨询能力，帮助用<br />户理解情感并应对情绪问题   | 8K   | 4k   |
| CodeGeeX-4 | 代码模型  | 适用于代码自动补全任务                      | 128K | 32k  |
| Rerank     | 重排序模型 | 计算文本之间的 score 值，<br />对召回结果进行重排序 | 4K   | -    |

### 即将弃用模型

我们已经宣布了以下模型的弃用日期。在这些模型弃用后，我们会将它们自动路由至新的模型。请用户注意在弃用日期之前，将您的模型编码更新为最新版本，以确保服务的顺畅过渡。

| 模型         | 弃用时间        | 指向模型 |
| :--------- | :---------- | :--- |
| GLM-Z1系列   | 2025年11月15日 | -    |
| GLM-4-0520 | 2025年12月30日 | -    |




> ## Documentation Index
> Fetch the complete documentation index at: https://docs.bigmodel.cn/llms.txt
> Use this file to discover all available pages before exploring further.

# 平台介绍

> Z智谱·一站式大模型开发平台

<Frame>
  <img className="block dark:hidden" src="https://cdn.bigmodel.cn/static/logo/dark.svg" alt="智谱AI开放平台" />

  <img className="hidden dark:block" src="https://cdn.bigmodel.cn/static/logo/light.svg" alt="智谱AI开放平台" />
</Frame>

## 平台定位

智谱大模型开放平台 [bigmodel.cn](http://bigmodel.cn)，提供功能丰富、灵活易用、高性价比的大模型 API 服务，支持智能体开发与模型精调、推理、评测等，致力于构建高效通用的“一站式模型即服务” AI 开发新范式。

## 平台优势

<CardGroup cols={2}>
  <Card title="模型矩阵" icon={<svg style={{maskImage: "url(/resource/icon/book-open.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
    全模态、全尺寸、低幻觉、高精度
  </Card>

  <Card title="开发套件" icon={<svg style={{maskImage: "url(/resource/icon/flask.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
    覆盖模型与 AI 应用开发，全链路开箱即用
  </Card>

  <Card title="深耕场景" icon={<svg style={{maskImage: "url(/resource/icon/list.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
    深度耦合业务的应用级 Agent，直达生产力
  </Card>

  <Card title="服务保障" icon={<svg style={{maskImage: "url(/resource/icon/helmet-safety.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
    充沛高并发算力资源，多层次安全防护机制
  </Card>
</CardGroup>

## 查看模型

平台已上架数十个模型，覆盖文本生成、语言推理、图像理解、视频生成、音视频处理等多场景。前往 [模型概览](/cn/guide/start/model-overview)，即可查看所有模型的功能定位、模型价格、上下文长度等基本信息。

## 极速体验

您可前往智谱大模型 [体验中心](https://bigmodel.cn/trialcenter/modeltrial)，极速体验模型能力。

<Tip>
  在对话框输入相关参数及prompt，点击发送，即可看到对应模型所输出的结果。

  ![](https://cdn.bigmodel.cn/static/logo/introduction.png)

  点击页面左侧的按钮，可自由切换体验文本模态、多模态模型及数十种智能体。
</Tip>

## 快速开始

[快速开始](/cn/guide/start/quick-start) 将引导您逐步完成 API 调用流程，涵盖注册账号、环境配置、获取 API key、SDK 使用等关键步骤。帮助您分钟级完成模型调用服务，并集成到您的业务或应用中。

## 开发指南

平台提供多种开发方式，满足不同开发者的需求和技术栈偏好。无论您是初学者还是经验丰富的开发者，都能找到适合的集成方案。

<CardGroup cols={2}>
  <Card title="HTTP API 调用" href="/cn/guide/develop/http/introduction">
    标准 RESTful API 接口，支持所有编程语言和平台
  </Card>

  <Card title="官方 Python SDK" href="/cn/guide/develop/python/introduction">
    功能完整的 Python 开发工具包，支持异步调用和类型安全
  </Card>

  <Card title="官方 Java SDK" href="/cn/guide/develop/java/introduction">
    企业级 Java 开发工具包，支持高并发和高可用性
  </Card>

  <Card title="OpenAI SDK 兼容" href="/cn/guide/develop/openai/introduction">
    兼容 OpenAI SDK，零学习成本快速迁移现有应用
  </Card>

  <Card title="LangChain 集成" href="/cn/guide/develop/langchain/introduction">
    集成 LangChain 框架，构建复杂的 AI 应用和智能代理
  </Card>
</CardGroup>

## 核心概念

<Tabs>
  <Tab title="GLM">
    <Card title="GLM - General Language Model" icon={<svg style={{maskImage: "url(/resource/icon/brain.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
      GLM 是一款基于自回归填空的预训练语言模型。ChatGLM 系列模型，支持相对复杂的自然语言指令，并且能够解决困难的推理类问题。该模型配备了易于使用的 API 接口，允许开发者轻松将其融入各类应用，广泛应用于智能客服、虚拟主播、聊天机器人等诸多领域。
    </Card>
  </Tab>

  <Tab title="Token">
    <Card title="Token - 文本处理单位" icon={<svg style={{maskImage: "url(/resource/icon/coins.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
      Token 是模型用来表示自然语言文本的基本单位，可以直观的理解为“字”或“词”；通常 1 个中文词语、1 个英文单词、1 个数字或 1 个符号计为 1 个 token。
      GLM 系列模型中 token 和字数的换算比例约为 1:1.6 ，但因为不同模型的分词不同，所以换算比例也存在差异，每一次实际处理 token 数量以模型返回为准，您可以从返回结果的 usage 中查看。
    </Card>
  </Tab>

  <Tab title="上下文窗口">
    <Card title="Context Window - 上下文窗口" icon={<svg style={{maskImage: "url(/resource/icon/window.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
      上下文窗口是指模型在一次对话中能够处理的最大长度。包括：

      * 用户输入的内容
      * 模型生成的回复
      * 模型在生成回复过程中进行推理或调用工具时产生的中间内容（如：GLM-4-AllTools ）

      <br />

      <Danger>
        如果超出上下文窗口限制，会发生什么？

        1. 超出部分被截断：
           如果总文本量超过了上下文窗口的限制，超出的部分将被自动丢弃，无法被处理。
        2. 影响对话内容：
           你可能看不到被丢弃的部分，从而影响模型的回答质量或上下文的连贯性。
      </Danger>
    </Card>
  </Tab>
</Tabs>

查看模型的上下文限制，或者使用 Tokenizer 工具估算上下文长度。

<Note>
  **重要提醒**：以上内容主要适用于 GLM-4 系列语言模型。对于多模态模型，输入内容有严格长度限制，若超出限制，系统将提示"prompt 超长"。
</Note>





> ## Documentation Index
> Fetch the complete documentation index at: https://docs.bigmodel.cn/llms.txt
> Use this file to discover all available pages before exploring further.

# 快速开始

<Tip>
  本指南将帮助您快速上手智谱开放平台，从注册账号到发起第一次 API 调用，只需几分钟即可完成。
</Tip>

## 开始使用

<Steps>
  <Step title="注册账号">
    访问[智谱开放平台](https://open.bigmodel.cn)，点击右上角的「注册/登录」按钮，按照提示完成账号注册流程。

    <Frame>
      ![注册账号](https://cdn.bigmodel.cn/static/logo/register.png)
    </Frame>
  </Step>

  <Step title="获取API Key">
    登录后，在个人中心页面，点击 [API Keys](https://bigmodel.cn/usercenter/proj-mgmt/apikeys)，创建一个新的 API Key。

    <Warning>
      请妥善保管您的 API Key，不要泄露给他人，也不要直接硬编码在代码中。建议使用环境变量或配置文件来存储 API Key。
    </Warning>

    <Frame>
      ![获取 API Key](https://cdn.bigmodel.cn/static/logo/api-key.png)
    </Frame>
  </Step>

  <Step title="选择模型">
    平台提供多种模型，您可以根据自己的需求选择合适的模型。详细的模型介绍请参考[模型概况](/cn/guide/start/model-overview)。

    <CardGroup cols={2}>
      <Card title="GLM-4.7" icon={<svg style={{maskImage: "url(/resource/icon/book-open.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="/cn/guide/models/text/glm-4.7">
        通用旗舰大语言模型
      </Card>

      <Card title="GLM-4.6V" icon={<svg style={{maskImage: "url(/resource/icon/eye.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="/cn/guide/models/vlm/glm-4.6v">
        最新一代基于 MOE 架构的视觉推理模型
      </Card>

      <Card title="GLM-Image" icon={<svg style={{maskImage: "url(/resource/icon/image.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="/cn/guide/models/image-generation/glm-image">
        图像生成模型，文字渲染更稳更准
      </Card>

      <Card title="CogVideoX-3" icon={<svg style={{maskImage: "url(/resource/icon/video.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="/cn/guide/models/video-generation/cogvideox-3">
        视频生成模型，新增首尾帧生成
      </Card>
    </CardGroup>
  </Step>

  <Step title="选择开发方式">
    平台提供多种开发方式，您可以根据项目需求和技术栈选择最适合的方式：

    <CardGroup cols={2}>
      <Card title="HTTP API" icon={<svg style={{maskImage: "url(/resource/icon/globe.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="/cn/guide/develop/http/introduction">
        标准 RESTful API，支持所有编程语言和开发框架
      </Card>

      <Card title="Python SDK" icon={<svg style={{maskImage: "url(/resource/icon/python.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="/cn/guide/develop/python/introduction">
        官方 Python 开发工具包，提供完整的类型提示和异步支持
      </Card>

      <Card title="Java SDK" icon={<svg style={{maskImage: "url(/resource/icon/java.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="/cn/guide/develop/java/introduction">
        企业级 Java 开发工具包，支持高并发和高可用性
      </Card>

      <Card title="API 参考文档" icon={<svg style={{maskImage: "url(/resource/icon/book.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="/cn/api/introduction">
        完整的 API 接口文档和参数说明
      </Card>
    </CardGroup>
  </Step>

  <Step title="发起调用">
    准备好 `API Key` 和选择模型后，您可以开始发起调用。以下是使用 `curl` 和 `Python SDK` `Java SDK` 的示例：

    <Tabs>
      <Tab title="cURL">
        <Warning>
          注意：使用 [GLM 编码套餐](/cn/coding-plan/overview) 时，需要配置专属的 \
          Coding 端点 - [https://open.bigmodel.cn/api/coding/paas/v4](https://open.bigmodel.cn/api/coding/paas/v4) \
          而非通用端点 - [https://open.bigmodel.cn/api/paas/v4/](https://open.bigmodel.cn/api/paas/v4/) \
          注意：Coding API 端点仅限 Coding 场景，并不适用通用 API 场景，请区分使用。
        </Warning>

        ```bash  theme={null}
        curl -X POST "https://open.bigmodel.cn/api/paas/v4/chat/completions" \
        -H "Content-Type: application/json" \
        -H "Authorization: Bearer YOUR_API_KEY" \
        -d '{
            "model": "glm-4.7",
            "messages": [
                {
                    "role": "system",
                    "content": "你是一个有用的AI助手。"
                },
                {
                    "role": "user",
                    "content": "你好，请介绍一下自己。"
                }
            ],
            "temperature": 1.0,
            "stream": true
        }'
        ```
      </Tab>

      <Tab title="Python SDK">
        **安装 SDK**

        ```bash  theme={null}
        # 安装最新版本
        pip install zai-sdk

        # 或指定版本
        pip install zai-sdk==0.2.2
        ```

        **验证安装**

        ```python  theme={null}
        import zai
        print(zai.__version__)
        ```

        **使用示例**

        ```python  theme={null}
        from zai import ZhipuAiClient

        # 初始化客户端
        client = ZhipuAiClient(api_key="YOUR_API_KEY")

        # 创建聊天完成请求
        response = client.chat.completions.create(
            model="glm-4.7",
            messages=[
                {
                    "role": "system",
                    "content": "你是一个有用的AI助手。"
                },
                {
                    "role": "user",
                    "content": "你好，请介绍一下自己。"
                }
            ],
            temperature=0.6
        )

        # 获取回复
        print(response.choices[0].message.content)
        ```
      </Tab>

      <Tab title="Java SDK">
        **安装 SDK**

        **Maven**

        ```xml  theme={null}
        <dependency>
            <groupId>ai.z.openapi</groupId>
            <artifactId>zai-sdk</artifactId>
            <version>0.3.3</version>
        </dependency>
        ```

        **Gradle (Groovy)**

        ```groovy  theme={null}
        implementation 'ai.z.openapi:zai-sdk:0.3.3'
        ```

        **使用示例**

        ```java  theme={null}
        import ai.z.openapi.ZhipuAiClient;
        import ai.z.openapi.service.model.*;
        import java.util.Arrays;

        public class QuickStart {
            public static void main(String[] args) {
                // 初始化客户端
                ZhipuAiClient client = ZhipuAiClient.builder().ofZHIPU()
                    .apiKey("YOUR_API_KEY")
                    .build();

                // 创建聊天完成请求
                ChatCompletionCreateParams request = ChatCompletionCreateParams.builder()
                    .model("glm-4.7")
                    .messages(Arrays.asList(
                        ChatMessage.builder()
                            .role(ChatMessageRole.USER.value())
                            .content("Hello, who are you?")
                            .build()
                    ))
                    .stream(false)
                    .temperature(0.6f)
                    .maxTokens(1024)
                    .build();

                // 发送请求
                ChatCompletionResponse response = client.chat().createChatCompletion(request);

                // 获取回复
                System.out.println(response.getData().getChoices().get(0).getMessage());
            }
        }
        ```
      </Tab>

      <Tab title="Python SDK(旧)">
        **安装 SDK**

        ```bash  theme={null}
        # 安装最新版本
        pip install zhipuai

        # 或指定版本
        pip install zhipuai==2.1.5.20250726
        ```

        **验证安装**

        ```python  theme={null}
        import zhipuai
        print(zhipuai.__version__)
        ```

        **使用示例**

        ```python  theme={null}
        from zhipuai import ZhipuAI

        client = ZhipuAI(api_key="YOUR_API_KEY")
        response = client.chat.completions.create(
            model="glm-4.7",
            messages=[
                {
                    "role": "system",
                    "content": "你是一个有用的AI助手。"
                },
                {
                    "role": "user",
                    "content": "你好，请介绍一下自己。"
                }
            ]
        )
        print(response.choices[0].message.content)
        ```
      </Tab>
    </Tabs>
  </Step>
</Steps>

## 探索更多功能

<Card title="流式输出" icon={<svg style={{maskImage: "url(/resource/icon/water.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
  启用流式输出，获得更自然的对话体验。

  ```json  theme={null}
  {
      "model": "glm-4.7",
      "messages": [
          {
              "role": "user",
              "content": "你好，请介绍一下自己。"
          }
      ],
      "stream": true
  }
  ```
</Card>

<Card title="多模态输入" icon={<svg style={{maskImage: "url(/resource/icon/images.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
  使用 GLM-4.6V 模型处理图像和文本的混合输入。

  ```json  theme={null}
  {
      "model": "glm-4.6v",
      "messages": [
          {
              "role": "user",
              "content": [
                  {
                      "type": "text",
                      "text": "这张图片是什么?"
                  },
                  {
                      "type": "image_url",
                      "image_url": {
                          "url": "data:image/jpeg;base64,..."
                      }
                  }
              ]
          }
      ]
  }
  ```
</Card>

<Card title="函数调用" icon={<svg style={{maskImage: "url(/resource/icon/function.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
  使用函数调用功能，让模型调用您定义的函数。

  ```json  theme={null}
  {
      "model": "glm-4.7",
      "messages": [
          {
              "type": "text",
              "text": "帮我查询从2024年1月20日，从北京出发前往上海的航班"
          }
      ],
      "tools": [
          {
              "type": "function",
              "function": {
                  "name": "get_flight_number",
                  "description": "根据始发地、目的地和日期，查询对应日期的航班号",
                  "parameters": {
                      "type": "object",
                      "properties": {
                          "departure": {
                              "description": "出发地",
                              "type": "string"
                          },
                          "destination": {
                              "description": "目的地",
                              "type": "string"
                          },
                          "date": {
                              "description": "日期",
                              "type": "string"
                          }
                      },
                      "required": ["departure", "destination", "date"]
                  }
              }
          }
      ]
  }
  ```
</Card>

## 常见问题

<AccordionGroup>
  <Accordion title="如何处理API调用错误？">
    当 API 调用出现错误时，服务器会返回相应的 HTTP 状态码和错误信息。常见的错误包括：

    * **401 Unauthorized**: API Key 无效或已过期
    * **400 Bad Request**: 请求参数错误
    * **429 Too Many Requests**: 超出 API 调用频率限制
    * **500 Internal Server Error**: 服务器内部错误

    建议实现适当的错误处理和重试机制，特别是对于 429 和 500 错误。
  </Accordion>

  <Accordion title="如何优化API调用成本？">
    以下是一些优化 API 调用成本的建议：

    1. 选择适合任务的模型，不同模型的价格不同
    2. 减少不必要的上下文信息，降低 token 消耗
    3. 使用缓存机制，避免重复调用
    4. 设置合理的 max\_tokens 参数，避免生成过长的回复
    5. 在开发阶段使用较小的模型进行测试
  </Accordion>

  <Accordion title="如何处理长文本输入？">
    对于超过模型上下文窗口大小的长文本，可以采用以下策略：

    1. 使用 GLM-4-Long 等支持更长上下文的模型
    2. 对文本进行分段处理，然后合并结果
    3. 使用文本嵌入模型进行相关性检索，只保留最相关的部分
    4. 对文本进行摘要，提取关键信息后再输入模型
  </Accordion>
</AccordionGroup>

<Tip>
  如果您在使用过程中遇到任何问题，可以查阅 [完整文档](/cn/faq/api-code) 或联系我们的 [技术支持](https://bigmodel.cn/online-book/customerService) 。
</Tip>


> ## Documentation Index
> Fetch the complete documentation index at: https://docs.bigmodel.cn/llms.txt
> Use this file to discover all available pages before exploring further.

# 核心参数

<Tip>
  在与模型进行交互时，你可以通过调整不同的参数来控制模型的输出，以满足不同场景下的需求。理解这些核心参数将帮助你更好地利用模型的能力。
</Tip>

## 快速参考

| 参数                          | 类型  | 默认值                   | 描述                                |
| :-------------------------- | :-- | :-------------------- | :-------------------------------- |
| [do\_sample](#do_sample)    | 布尔值 | `true`                | 是否对输出进行采样，以增加多样性。                 |
| [temperature](#temperature) | 浮点数 | (依赖模型)                | 控制输出的随机性，值越高越随机。                  |
| [top\_p](#top_p)            | 浮点数 | (依赖模型)                | 通过核采样控制多样性，建议与 `temperature` 二选一。 |
| [max\_tokens](#max_tokens)  | 整数  | (依赖模型)                | 限制单次调用生成的最大 token 数。              |
| [stream](#stream)           | 布尔值 | `false`               | 是否以流式方式返回响应。                      |
| [thinking](#thinking)       | 对象  | `{"type": "enabled"}` | 是否开启思维链深度思考，仅 `GLM-4.5` 及以上支持。    |

***

## 参数详解

### do\_sample

`do_sample` 是一个布尔值（`true` 或 `false`），用于决定是否对模型的输出进行采样。

* `true` (默认值): 根据每个 token 的概率分布进行随机采样，增加文本的多样性和创造性。适用于内容创作、对话等场景。
* `false`: 采用贪心策略，总是选择概率最高的下一个 token。输出确定性高，适用于需要精确、事实性回答的场景。

最佳实践:

* 需要可复现、确定性的输出时，设为 `false`。
* 希望模型生成更多样、更有趣的内容时，设为 `true`，并配合 `temperature` 或 `top_p` 使用。

### temperature

`temperature`（温度）参数控制着模型输出的随机性。

* 较低的值 (如 0.2): 概率分布更“尖锐”，输出更具确定性、更保守。
* 较高的值 (如 0.8): 概率分布更“平缓”，输出更具随机性和多样性。

最佳实践:

* 在需要严谨、事实准确的场景（如知识问答），建议使用较低的 `temperature`。
* 在需要创意的场景（如内容创作），可以尝试较高的 `temperature`。
* 建议 `temperature` 和 `top_p` 只使用其中一个。

### top\_p

`top_p`（核采样）通过从累积概率超过阈值的最小 token 集合中进行采样来控制多样性。

* 较低的值 (如 0.2): 限制采样范围，输出更具确定性。
* 较高的值 (如 0.9): 扩大采样范围，输出更具多样性。

最佳实践:

* 如果希望在保证内容质量的同时获得一定的多样性，`top_p` 是一个很好的选择（推荐值 0.8-0.95）。
* 通常不建议同时修改 `temperature` 和 `top_p`。

### max\_tokens

`max_tokens` 用于限制模型单次调用生成的最大 token 数量。GLM-4.6 最大支持 128K 输出长度，GLM-4.5 最大支持 96K 输出长度，建议设置不小于 1024。令牌是文本的基本单位，通常 1 个令牌约等于 0.75 个英文单词或 1.5 个中文字符。设置合适的 max\_tokens 可以控制响应长度和成本，避免过长的输出。如果模型在达到 max\_tokens 限制前完成回答，会自然结束；如果达到限制，输出可能被截断。

* 作用: 防止生成过长文本，控制 API 调用成本。
* 注意: `max_tokens` 限制的是生成内容的长度，不包括输入。

最佳实践:

* 根据应用场景合理设置 `max_tokens`。如果需要简短回答，可设为较小的值（如 50）。

各模型的默认 `max_tokens` 和支持的最大 `max_tokens`:

| 模型编码                     | 默认 max\_tokens | 最大 max\_tokens |
| :----------------------- | :------------: | :------------: |
| glm-4.7                  |      65536     |     131072     |
| glm-4.6                  |      65536     |     131072     |
| glm-4.6v                 |      16384     |      32768     |
| glm-4.6v-flash           |      16384     |      32768     |
| glm-4.6v-flashx          |      16384     |      32768     |
| glm-4.5                  |      65536     |      98304     |
| glm-4.5-air              |      65536     |      98304     |
| glm-4.5-x                |      65536     |      98304     |
| glm-4.5-flash            |      65536     |      98304     |
| glm-4.5v                 |      16384     |      16384     |
| glm-4.1v-thinking-flashx |      32768     |      32768     |
| glm-4.1v-thinking-flash  |      32768     |      32768     |
| glm-4-air-250414         |      16384     |      16384     |
| glm-4-flash-250414       |      32768     |      32768     |
| glm-4-plus               |      动态计算      |      4095      |
| glm-4-air                |      动态计算      |      4095      |
| glm-4-airx               |      动态计算      |      4095      |
| glm-4-flash              |      动态计算      |      4095      |
| glm-4-flashx             |      动态计算      |      4095      |
| glm-4v-plus-0111         |      1024      |      8192      |
| glm-4v-flash             |      1024      |      1024      |

### stream

`stream` 是一个布尔值，用于控制 API 的响应方式。

* `false` (默认值): 一次性返回完整的响应，实现简单但等待时间长。
* `true`: 以流式（SSE）方式返回内容，显著提升实时交互应用的体验。

最佳实践:

* 对于聊天机器人、实时代码生成等应用，强烈建议设为 `true`。

### thinking

`thinking` 参数用于控制模型是否开启“思维链”（Chain of Thought），以进行更深度的思考和推理。

* 类型: 对象
* 支持模型: `GLM-4.5` 及以上

属性:

* `type` (string):
  * `enabled` (默认): 开启思维链。`GLM-4.6` `GLM-4.5` 会自动判断是否需要，而 `GLM-4.5V` 会强制思考。
  * `disabled`: 关闭思维链。

最佳实践:

* 在需要模型进行复杂推理、规划时，建议开启。
* 对于简单任务，可关闭以获得更快响应。

***

## 相关概念

<AccordionGroup>
  <Accordion title="Token 用量计算">
    Token 是模型处理文本的基本单位。用量计算包括输入和输出两部分。

    * **输入 Token 数:** 你发送给模型的文本所包含的 token 数量。
    * **输出 Token 数:** 模型生成的文本所包含的 token 数量。
    * **总 Token 数:** 输入与输出之和，通常为计费依据。

    你可以调用 `tokenizer` 分词器 API 来预估文本的 token 数量。
  </Accordion>

  <Accordion title="最大输出 Tokens">
    最大输出 Tokens 是指模型在单次请求中能够生成的最大 Token 数量。它与 `max_tokens` 参数不同，`max_tokens` 是你在请求中设置的上限，而最大输出 Tokens 是模型本身的架构限制。

    例如，一个模型的上下文窗口可能是 8k Tokens，但其最大输出能力可能被限制在 4k Tokens。
  </Accordion>

  <Accordion title="上下文窗口">
    上下文窗口（Context Window）是指模型在一次交互中能够处理的总 Token 数量，它包括了**输入文本**和**生成文本**的所有 Token。

    * **重要性:** 上下文窗口决定了模型能“记住”多少历史信息。如果输入和期望输出的总长度超过了模型的上下文窗口，模型将无法处理。
    * **注意:** 不同模型的上下文窗口大小不同。在进行长对话或处理长文档时，需要特别关注上下文窗口的限制。
  </Accordion>

  <Accordion title="并发数权益">
    并发数（Concurrency）是指你在同一时间内可以发起的 API 请求数量。这是平台为了保证服务稳定性和公平分配资源而设置的。

    * **权益:** 不同的用户或订阅计划可能拥有不同的并发数配额。
    * **超额:** 如果超出并发数限制，新的请求可能会失败或需要排队等待。

    如果你的应用需要高并发处理，请检查你的账户权益或联系平台支持。
  </Accordion>
</AccordionGroup>

***

希望这份文档能帮助你更好地理解和使用 API 的核心参数！




> ## Documentation Index
> Fetch the complete documentation index at: https://docs.bigmodel.cn/llms.txt
> Use this file to discover all available pages before exploring further.

# HTTP API 调用

智谱AI 提供基于 RESTful 架构的应用程序接口，通过标准的 HTTP 协议与智谱AI 的模型服务进行交互。无论您使用什么编程语言或开发框架，都可以通过 HTTP 请求来调用智谱AI 的各种 AI 模型。

### 核心优势

<CardGroup cols={2}>
  <Card title="跨平台兼容" icon={<svg style={{maskImage: "url(/resource/icon/globe.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
    支持所有支持 HTTP 协议的编程语言和平台
  </Card>

  <Card title="标准协议" icon={<svg style={{maskImage: "url(/resource/icon/shield-check.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
    基于 RESTful 设计，遵循 HTTP 标准，易于理解和使用
  </Card>

  <Card title="灵活集成" icon={<svg style={{maskImage: "url(/resource/icon/puzzle-piece.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
    可以集成到任何现有的应用程序和系统中
  </Card>

  <Card title="实时调用" icon={<svg style={{maskImage: "url(/resource/icon/bolt.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
    支持同步和异步调用，满足不同场景需求
  </Card>
</CardGroup>

## 获取 API Key

1. 访问 [智谱AI 开放平台](https://bigmodel.cn)
2. 注册并登录您的账户
3. 在 [API Keys](https://bigmodel.cn/usercenter/proj-mgmt/apikeys) 管理页面创建 API Key
4. 复制您的 API Key 以供使用

<Tip>
  建议将 API Key 设置为环境变量替代硬编码到代码中，以提高安全性。
</Tip>

## API 基础信息

### 请求端点(通用API)

```
https://open.bigmodel.cn/api/paas/v4/
```

<Warning>
  注意：使用 [GLM 编码套餐](/cn/coding-plan/overview) 时，需要配置专属的 \
  Coding 端点 - [https://open.bigmodel.cn/api/coding/paas/v4](https://open.bigmodel.cn/api/coding/paas/v4) \
  而非通用端点 - [https://open.bigmodel.cn/api/paas/v4/](https://open.bigmodel.cn/api/paas/v4/) \
  注意：Coding API 端点仅限 Coding 场景，并不适用通用 API 场景，请区分使用。
</Warning>

### 请求头要求

<mcreference link="https://bigmodel.cn/dev/api/http-call/http-para" index="0">0</mcreference>

```http  theme={null}
Content-Type: application/json
Authorization: Bearer YOUR_API_KEY
```

### 支持的鉴权方式

<Tabs>
  <Tab title="API Key 鉴权">
    最简单的鉴权方式，直接使用您的 API Key：

    ```bash  theme={null}
    curl --location 'https://open.bigmodel.cn/api/paas/v4/chat/completions' \
    --header 'Authorization: Bearer YOUR_API_KEY' \
    --header 'Content-Type: application/json' \
    --data '{
        "model": "glm-4.7",
        "messages": [
            {
                "role": "user",
                "content": "你好"
            }
        ]
    }'
    ```
  </Tab>

  <Tab title="JWT Token 鉴权">
    使用 JWT Token 进行鉴权，适合需要更高安全性的场景：
    安装依赖 PyJWT

    ```shell  theme={null}
    pip install PyJWT
    ```

    ```python  theme={null}
    import time
    import jwt

    def generate_token(apikey: str, exp_seconds: int):
        try:
            id, secret = apikey.split(".")
        except Exception as e:
            raise Exception("invalid apikey", e)

        payload = {
            "api_key": id,
            "exp": int(round(time.time() * 1000)) + exp_seconds * 1000,
            "timestamp": int(round(time.time() * 1000)),
        }

        return jwt.encode(
            payload,
            secret,
            algorithm="HS256",
            headers={"alg": "HS256", "sign_type": "SIGN"},
        )

    # 使用生成的 token
    token = generate_token("your-api-key", 3600)  # 1 小时有效期
    ```
  </Tab>
</Tabs>

## 基础调用示例

### 简单对话

```bash  theme={null}
curl --location 'https://open.bigmodel.cn/api/paas/v4/chat/completions' \
--header 'Authorization: Bearer YOUR_API_KEY' \
--header 'Content-Type: application/json' \
--data '{
    "model": "glm-4.7",
    "messages": [
        {
            "role": "user",
            "content": "请介绍一下人工智能的发展历程"
        }
    ],
    "temperature": 1.0,
    "max_tokens": 1024
}'
```

### 流式响应

```bash  theme={null}
curl --location 'https://open.bigmodel.cn/api/paas/v4/chat/completions' \
--header 'Authorization: Bearer YOUR_API_KEY' \
--header 'Content-Type: application/json' \
--data '{
    "model": "glm-4.7",
    "messages": [
        {
            "role": "user",
            "content": "写一首关于春天的诗"
        }
    ],
    "stream": true
}'
```

### 多轮对话

```bash  theme={null}
curl --location 'https://open.bigmodel.cn/api/paas/v4/chat/completions' \
--header 'Authorization: Bearer YOUR_API_KEY' \
--header 'Content-Type: application/json' \
--data '{
    "model": "glm-4.7",
    "messages": [
        {
            "role": "system",
            "content": "你是一个专业的编程助手"
        },
        {
            "role": "user",
            "content": "什么是递归？"
        },
        {
            "role": "assistant",
            "content": "递归是一种编程技术，函数调用自身来解决问题..."
        },
        {
            "role": "user",
            "content": "能给我一个 Python 递归的例子吗？"
        }
    ]
}'
```

## 常用编程语言示例

<Tabs>
  <Tab title="Python">
    ```python  theme={null}
    import requests
    import json

    def call_zhipu_api(messages, model="glm-4.7"):
        url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"

        headers = {
            "Authorization": "Bearer YOUR_API_KEY",
            "Content-Type": "application/json"
        }

        data = {
            "model": model,
            "messages": messages,
            "temperature": 1.0
        }

        response = requests.post(url, headers=headers, json=data)

        if response.status_code == 200:
            return response.json()
        else:
            raise Exception(f"API调用失败: {response.status_code}, {response.text}")

    # 使用示例
    messages = [
        {"role": "user", "content": "你好，请介绍一下自己"}
    ]

    result = call_zhipu_api(messages)
    print(result['choices'][0]['message']['content'])
    ```
  </Tab>

  <Tab title="JavaScript">
    ```javascript  theme={null}
    async function callZhipuAPI(messages, model = 'glm-4.7') {
        const url = 'https://open.bigmodel.cn/api/paas/v4/chat/completions';

        const response = await fetch(url, {
            method: 'POST',
            headers: {
                'Authorization': 'Bearer YOUR_API_KEY',
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                model: model,
                messages: messages,
                temperature: 1.0
            })
        });

        if (!response.ok) {
            throw new Error(`API 调用失败: ${response.status}`);
        }

        return await response.json();
    }

    // 使用示例
    const messages = [
        { role: 'user', content: '你好，请介绍一下自己' }
    ];

    callZhipuAPI(messages)
        .then(result => {
            console.log(result.choices[0].message.content);
        })
        .catch(error => {
            console.error('错误:', error);
        });
    ```
  </Tab>

  <Tab title="Java">
    ```java  theme={null}
    import com.fasterxml.jackson.databind.ObjectMapper;
    import okhttp3.MediaType;
    import okhttp3.OkHttpClient;
    import okhttp3.Request;
    import okhttp3.RequestBody;
    import okhttp3.Response;
    import java.util.Collections;
    import java.util.HashMap;
    import java.util.Map;

    public class AgentExample {

        public static void main(String[] args) throws Exception {

            OkHttpClient client = new OkHttpClient();
            ObjectMapper mapper = new ObjectMapper();
            Map<String, String> messages = new HashMap<>(8);
            messages.put("role", "user");
            messages.put("content", "你好，请介绍一下自己");
            Map<String, Object> requestBody = new HashMap<>();
            requestBody.put("model", "glm-4.7");
            requestBody.put("messages", Collections.singletonList(messages));
            requestBody.put("temperature", 1.0);

            String jsonBody = mapper.writeValueAsString(requestBody);
            MediaType JSON = MediaType.get("application/json; charset=utf-8");
            RequestBody body = RequestBody.create(JSON, jsonBody);
            Request request = new Request.Builder()
                .url("https://open.bigmodel.cn/api/paas/v4/chat/completions")
                .addHeader("Authorization", "Bearer your_api_key")
                .addHeader("Content-Type", "application/json")
                .post(body)
                .build();
            try (Response response = client.newCall(request).execute()) {
                System.out.println(response.body().string());
            }
        }
    }
    ```
  </Tab>
</Tabs>

## 错误处理

### 常见错误码

| 错误码 | 说明      | 解决方案            |
| --- | ------- | --------------- |
| 401 | 未授权     | 检查 API Key 是否正确 |
| 429 | 请求过于频繁  | 降低请求频率，实施重试机制   |
| 500 | 服务器内部错误 | 稍后重试，如持续出现请联系支持 |

更多错误码和解决方案请参考 [API 错误码文档](/cn/faq/api-code)

## 实践建议

<CardGroup cols={2}>
  <Card title="安全性">
    * 妥善保管 API Key，不要在代码中硬编码
    * 使用环境变量或配置文件存储敏感信息
    * 定期轮换 API Key
  </Card>

  <Card title="性能优化">
    * 实施连接池和会话复用
    * 合理设置超时时间
    * 使用异步请求处理高并发场景
  </Card>

  <Card title="错误处理">
    * 实施指数退避重试机制
    * 记录详细的错误日志
    * 设置合理的超时和重试次数
  </Card>

  <Card title="监控">
    * 监控 API 调用频率和成功率
    * 跟踪响应时间和错误率
    * 设置告警机制
  </Card>
</CardGroup>

## 更多资源

<CardGroup cols={2}>
  <Card title="API 文档" icon={<svg style={{maskImage: "url(/resource/icon/book.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="/cn/api/introduction">
    查看完整的 API 接口文档和参数说明
  </Card>

  <Card title="技术支持" icon={<svg style={{maskImage: "url(/resource/icon/headset.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="https://bigmodel.cn/online-book/customerService">
    获取技术支持和帮助
  </Card>
</CardGroup>

<Note>
  建议在生产环境中使用 HTTPS 协议，并实施适当的安全措施来保护您的 API 密钥和数据传输。
</Note>



> ## Documentation Index
> Fetch the complete documentation index at: https://docs.bigmodel.cn/llms.txt
> Use this file to discover all available pages before exploring further.

# 官方 Python SDK

Z.ai Python SDK 是一个智谱AI 官方提供的功能强大、易于使用的 Python 开发工具包，专为与智谱AI 的各种人工智能模型进行交互而设计，为 Python 开发者提供便捷、高效的AI 模型集成方案。

<Tip>
  最新 Python SDK 版本为 `0.2.0`, 请及时更新以获取最新功能和修复。
</Tip>

### 核心优势

<CardGroup cols={2}>
  <Card title="简单易用" icon={<svg style={{maskImage: "url(/resource/icon/rocket.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
    Pythonic 的 API 设计，完善的文档和示例，让您快速上手
  </Card>

  <Card title="功能完整" icon={<svg style={{maskImage: "url(/resource/icon/puzzle-piece.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
    支持智谱AI 全系列模型，包括语言、视觉、图像生成等
  </Card>

  <Card title="高性能" icon={<svg style={{maskImage: "url(/resource/icon/gauge-high.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
    异步支持、连接池管理，优化的网络请求处理
  </Card>

  <Card title="类型安全" icon={<svg style={{maskImage: "url(/resource/icon/shield-check.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
    完整的类型提示，IDE 友好，减少开发错误
  </Card>
</CardGroup>

### 支持的功能

* **对话聊天**：支持单轮和多轮对话，流式和非流式响应
* **函数调用**：让 AI 模型调用您的自定义函数
* **视觉理解**：图像分析、视觉问答
* **图像生成**：根据文本描述生成高质量图像
* **视频生成**：文本到视频的创意内容生成
* **语音处理**：语音转文字、文字转语音
* **文本嵌入**：文本向量化，支持语义搜索
* **智能助手**：构建专业的 AI 助手应用
* **内容审核**：文本和图像内容安全检测

## 技术规格

### 环境要求

* **Python 版本**：Python 3.8 或更高版本
* **包管理器**：pip 或 poetry
* **网络要求**：支持 HTTPS 连接
* **API 密钥**：需要有效的智谱AI API 密钥

### 依赖管理

SDK 采用模块化设计，您可以根据需要选择性安装功能模块：

* **核心模块**：基础 API 调用功能
* **异步模块**：异步和并发处理支持
* **工具模块**：实用工具和辅助功能

## 快速开始

### 环境要求

<CardGroup cols={2}>
  <Card title="Python 版本" icon={<svg style={{maskImage: "url(/resource/icon/python.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
    Python 3.8 或更高版本
  </Card>

  <Card title="包管理器" icon={<svg style={{maskImage: "url(/resource/icon/building.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>}>
    poetry（推荐）、uv（推荐）、pip
  </Card>
</CardGroup>

<Warning>
  支持 Python 3.8, 3.9, 3.10, 3.11, 3.12 版本，跨平台兼容 Windows、macOS、Linux
</Warning>

### 安装 SDK

#### 使用 pip 安装

```bash  theme={null}
# 安装最新版本
pip install zai-sdk

# 或指定版本
pip install zai-sdk==0.2.2
```

#### 验证安装

```python  theme={null}
import zai
print(zai.__version__)
```

### 获取 API Key

1. 访问 [Z 智谱开放平台](https://bigmodel.cn)
2. 注册并登录您的账户
3. 在 [API Keys](https://bigmodel.cn/usercenter/proj-mgmt/apikeys) 管理页面创建 API Key
4. 复制您的 API Key 以供使用

<Tip>
  建议将 API Key 设置为环境变量：`export ZAI_API_KEY=your-api-key` 替代硬编码到代码中，以提高安全性。
</Tip>

<Tip>
  国内智谱AI 平台使用 ZhipuAiClient 客户端
</Tip>

```
国内 API 地址: https://open.bigmodel.cn/api/paas/v4/
```

#### 创建客户端

<Tabs>
  <Tab title="环境变量">
    ```python  theme={null}
    from zai import ZhipuAiClient
    import os

    # 从环境变量读取 API Key
    client = ZhipuAiClient(api_key=os.getenv("ZAI_API_KEY"))

    # 或者直接使用（如果已设置环境变量）
    client = ZhipuAiClient()

    ```
  </Tab>

  <Tab title="直接设置">
    ```python  theme={null}
    from zai import ZaiClient, ZhipuAiClient

    # 直接设置 API Key
    client = ZhipuAiClient(api_key="abc123.def456")

    ```
  </Tab>
</Tabs>

#### 基础对话

```python  theme={null}
from zai import ZhipuAiClient

# Initialize client
client = ZhipuAiClient(api_key="your-api-key")

# Create chat completion
response = client.chat.completions.create(
    model="glm-4.7",
    messages=[
        {"role": "user", "content": "你好，请介绍一下自己, Z.ai!"}
    ]
)
print(response.choices[0].message.content)
```

#### 流式对话

```python  theme={null}
# 创建流式聊天请求
from zai import ZhipuAiClient

# Initialize client
client = ZhipuAiClient(api_key="your-api-key")

# Create chat completion
response = client.chat.completions.create(
    model='glm-4.7',
    messages=[
        {'role': 'system', 'content': '你是一个 AI 作家.'},
        {'role': 'user', 'content': '讲一个关于 AI 的故事.'},
    ],
    stream=True,
)

for chunk in response:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end='')
```

#### 多轮对话

```python  theme={null}
from zai import ZhipuAiClient
client = ZhipuAiClient(api_key="your-api-key")
response = client.chat.completions.create(
    model="glm-4.7",  # 请填写您要调用的模型名称
    messages=[
        {"role": "user", "content": "作为一名营销专家，请为我的产品创作一个吸引人的口号"},
        {"role": "assistant", "content": "当然，要创作一个吸引人的口号，请告诉我一些关于您产品的信息"},
        {"role": "user", "content": "智谱AI 开放平台"},
        {"role": "assistant", "content": "点燃未来，智谱AI 绘制无限，让创新触手可及！"},
        {"role": "user", "content": "创作一个更精准且吸引人的口号"}
    ],
)
print(response.choices[0].message.content)
```

### 完整示例

```python  theme={null}
from zai import ZhipuAiClient
import os

def main():
    # 初始化客户端
    client = ZhipuAiClient(api_key=os.getenv("ZAI_API_KEY"))
    
    print("欢迎使用 Z.ai 聊天机器人！输入 'quit' 退出。")
    
    # 对话历史
    conversation = [
        {"role": "system", "content": "你是一个友好的 AI 助手"}
    ]
    
    while True:
        # 获取用户输入
        user_input = input("您: ")
        
        if user_input.lower() == 'quit':
            break
        
        try:
            # 添加用户消息
            conversation.append({"role": "user", "content": user_input})
            
            # 创建聊天请求
            response = client.chat.completions.create(
                model="glm-4.7",
                messages=conversation,
                temperature=0.7,
                max_tokens=1000
            )
            
            # 获取 AI 回复
            ai_response = response.choices[0].message.content
            print(f"AI: {ai_response}")
            
            # 添加 AI 回复到对话历史
            conversation.append({"role": "assistant", "content": ai_response})
            
        except Exception as e:
            print(f"发生错误: {e}")
    
    print("再见！")

if __name__ == "__main__":
    main()
```

### 错误处理

```python  theme={null}
from zai import ZhipuAiClient
import zai

def robust_chat(message):
    client = ZhipuAiClient(api_key="your-api-key")
    
    try:
        response = client.chat.completions.create(
            model="glm-4.7",
            messages=[{"role": "user", "content": message}]
        )
        return response.choices[0].message.content
        
    except zai.core.APIStatusError as err:
        return f"API 状态错误: {err}"
    except zai.core.APITimeoutError as err:
        return f"请求超时: {err}"
    except Exception as err:
        return f"其他错误: {err}"

# 使用示例
result = robust_chat("你好")
print(result)
```

### 高级配置

```python  theme={null}
import httpx
from zai import ZhipuAiClient

# 自定义 HTTP 客户端
httpx_client = httpx.Client(
    limits=httpx.Limits(
        max_keepalive_connections=20,
        max_connections=100
    ),
    timeout=30.0
)

# 创建带自定义配置的客户端
client = ZhipuAiClient(
    api_key="your-api-key",
    base_url="https://open.bigmodel.cn/api/paas/v4/",
    timeout=httpx.Timeout(timeout=300.0, connect=8.0),
    max_retries=3,
    http_client=httpx_client
)
```

## 高级功能

### 推理（thinking）

在思考模式下，GLM-4.7 可以解决复杂的推理问题，包括数学、科学和逻辑问题。

```python  theme={null}
from zai import ZhipuAiClient
client = ZhipuAiClient(api_key='your-api-key')
response = client.chat.completions.create(
        model='glm-4.7',
        messages=[
            {"role": "system", "content": "you are a helpful assistant"},
            {"role": "user", "content": "what is the revolution of llm?"}
        ],
        stream=True,
        thinking={
            "type": "enabled"
        }
    )
for chunk in response:
    if chunk.choices[0].delta.reasoning_content:
        print(chunk.choices[0].delta.reasoning_content, end='')
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end='')
```

### 函数调用 (Function Calling)

函数调用允许 AI 模型调用您定义的函数来获取实时信息或执行特定操作。

#### 定义和使用函数

```python  theme={null}
from zai import ZhipuAiClient
import json

# 定义函数
def get_weather(location, date=None):
    """获取天气信息"""
    # 模拟天气 API 调用
    return {
        "location": location,
        "date": date or "今天",
        "weather": "晴天",
        "temperature": "25°C",
        "humidity": "60%"
    }

def get_stock_price(symbol):
    """获取股票价格"""
    # 模拟股票 API 调用
    return {
        "symbol": symbol,
        "price": 150.25,
        "change": "+2.5%"
    }

# 函数描述
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "获取指定地点的天气信息",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "地点名称"
                    },
                    "date": {
                        "type": "string",
                        "description": "日期，格式为 YYYY-MM-DD"
                    }
                },
                "required": ["location"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_stock_price",
            "description": "获取股票当前价格",
            "parameters": {
                "type": "object",
                "properties": {
                    "symbol": {
                        "type": "string",
                        "description": "股票代码"
                    }
                },
                "required": ["symbol"]
            }
        }
    }
]

# 使用函数调用
client = ZhipuAiClient(api_key="your-api-key")

response = client.chat.completions.create(
    model='glm-4.7',
    messages=[
        {'role': 'user', 'content': '北京今天天气怎么样？'}
    ],
    tools=tools,
    tool_choice="auto"
)

# 处理函数调用
if response.choices[0].message.tool_calls:
    for tool_call in response.choices[0].message.tool_calls:
        function_name = tool_call.function.name
        function_args = json.loads(tool_call.function.arguments)
        
        if function_name == "get_weather":
            result = get_weather(**function_args)
            print(f"天气信息：{result}")
        elif function_name == "get_stock_price":
            result = get_stock_price(**function_args)
            print(f"股票信息：{result}")
else:
    print(response.choices[0].message.content)
```

#### 网络搜索工具

```python  theme={null}
from zai import ZhipuAiClient

# 初始化客户端
client = ZhipuAiClient(api_key="your-api-key")

# 使用网络搜索工具
response = client.chat.completions.create(
    model='glm-4.7',
    messages=[
        {'role': 'system', 'content': 'You are a helpful assistant.'},
        {'role': 'user', 'content': 'What is artificial intelligence?'},
    ],
    tools=[
        {
            'type': 'web_search',
            'web_search': {
                'search_query': 'What is artificial intelligence?',
                'search_result': True,
            },
        }
    ],
    temperature=0.5,
    max_tokens=2000,
)

print(response)
```

### 多模态处理

#### 图像理解

```python  theme={null}
import base64
from zai import ZhipuAiClient

def encode_image(image_path):
    """将图像编码为 base64 格式"""
    with open(image_path, 'rb') as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

client = ZhipuAiClient(api_key="your-api-key")

# 方式1：使用图像URL
response = client.chat.completions.create(
    model="glm-4.6v",
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "这张图片里有什么？请详细描述。"
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://example.com/image.jpg"
                    }
                }
            ]
        }
    ]
)

print(response.choices[0].message.content)

# 方式2：使用base64编码的图像
base64_image = encode_image('path/to/your/image.jpg')

response = client.chat.completions.create(
    model="glm-4.6v",
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "分析这张图片中的内容"
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}"
                    }
                }
            ]
        }
    ]
)

print(response.choices[0].message.content)
```

#### 图像生成

```python  theme={null}
from zai import ZhipuAiClient

# Initialize client
client = ZhipuAiClient(api_key="your-api-key")

# 图像生成
response = client.images.generations(
    model="cogview-3",
    prompt="一幅美丽的山水画，中国传统风格，水墨画",
    size="1024x1024",
    quality="standard",
)

image_url = response.data[0].url
print(f"生成的图像URL: {image_url}")

# 高质量图像生成
response = client.images.generations(
    model="cogview-3-plus",
    prompt="未来城市的概念设计，科幻风格，高清细节",
    size="1024x1024",
    quality="hd",
)

image_url = response.data[0].url
print(f"生成的图像URL: {image_url}")
```

#### 视频生成

```python  theme={null}
from zai import ZhipuAiClient
import time

client = ZhipuAiClient(api_key="your-api-key")

# 提交生成任务
response = client.videos.generations(
    model="cogvideox-3",  # 使用的视频生成模型
    image_url=image_url,  # 提供的图片 URL 地址或者 Base64 编码
    prompt="让画面动起来",
    quality="speed",  # 输出模式，"quality"为质量优先，"speed"为速度优先
    with_audio=True,
    size="1920x1080",  # 视频分辨率，支持最高 4K（如: "3840x2160"）
    fps=30,  # 帧率，可选为 30 或 60
)
print(response)

# 获取生成结果
time.sleep(60)  # 等待一段时间以确保视频生成完成
result = client.videos.retrieve_videos_result(id=response.id)
print(result)
```

### 文本嵌入

```python  theme={null}
# 基础文本嵌入
from zai import ZhipuAiClient
client = ZhipuAiClient(api_key="your-api-key")

response = client.embeddings.create(
    model="embedding-3",
    input=[
        "这是第一段文本",
        "这是第二段文本",
        "这是第三段文本"
    ]
)

for i, embedding in enumerate(response.data):
    print(f"文本{i+1}的嵌入向量维度: {len(embedding.embedding)}")
    print(f"前5个维度的值: {embedding.embedding[:5]}")

# 计算文本相似度
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

def calculate_similarity(texts):
    """计算文本间的相似度"""
    response = client.embeddings.create(
        model="embedding-2",
        input=texts
    )
    
    embeddings = [data.embedding for data in response.data]
    embeddings_array = np.array(embeddings)
    
    # 计算余弦相似度
    similarity_matrix = cosine_similarity(embeddings_array)
    
    return similarity_matrix

# 使用示例
texts = [
    "我喜欢吃苹果",
    "苹果是我最爱的水果",
    "今天天气很好"
]

similarity = calculate_similarity(texts)
print("相似度矩阵:")
print(similarity)
```

### 流式处理

```python  theme={null}
class StreamProcessor:
    def __init__(self, client):
        self.client = client
        self.full_response = ""
    
    def stream_chat(self, messages, model="glm-4.7", callback=None):
        """流式聊天处理"""
        stream = self.client.chat.completions.create(
            model=model,
            messages=messages,
            stream=True
        )
        
        self.full_response = ""
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                content = chunk.choices[0].delta.content
                self.full_response += content
                
                if callback:
                    callback(content, self.full_response)
                else:
                    print(content, end="", flush=True)
        
        print()  # 换行
        return self.full_response

# 使用示例
processor = StreamProcessor(client)

# 自定义回调函数
def on_token_received(token, full_text):
    # 可以在这里实现实时处理逻辑
    print(token, end="", flush=True)

response = processor.stream_chat(
    messages=[{"role": "user", "content": "写一个 Python 函数来计算斐波那契数列"}],
    callback=on_token_received
)
```

## 更多资源

<CardGroup cols={2}>
  <Card title="GitHub 仓库" icon={<svg style={{maskImage: "url(/resource/icon/github.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="https://github.com/zai-org/z-ai-sdk-python">
    查看源代码、提交问题、参与贡献
  </Card>

  <Card title="API 参考" icon={<svg style={{maskImage: "url(/resource/icon/book.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="/cn/api/introduction">
    查看完整的 API 文档
  </Card>

  <Card title="示例项目" icon={<svg style={{maskImage: "url(/resource/icon/code.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="https://github.com/zai-org/z-ai-sdk-python/tree/main/examples">
    浏览更多实际应用示例
  </Card>

  <Card title="最佳实践" icon={<svg style={{maskImage: "url(/resource/icon/star.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="https://github.com/zai-org/z-ai-sdk-python">
    学习 SDK 使用的最佳实践
  </Card>
</CardGroup>

<Note>
  本 SDK 基于智谱AI 最新的 API 规范开发，确保与平台功能保持同步更新。建议定期更新到最新版本以获得最佳体验。
</Note>




> ## Documentation Index
> Fetch the complete documentation index at: https://docs.bigmodel.cn/llms.txt
> Use this file to discover all available pages before exploring further.

# 迁移至 GLM-4.7

<Tip>
  本文介绍如何将调用从 GLM-4.5 GLM-4.6 或其它早期模型迁移到我们迄今为止最强的编码模型 Z.ai GLM-4.7，涵盖采样参数差异、流式工具调用等要点。
</Tip>

## GLM-4.7 的特性

* 支持更大上下文与输出：最大上下文 200K，最大输出 128K。
* 新增支持工具调用过程的流式输出（`tool_stream=true`），实时获取工具调用参数。
* 同 GLM-4.6 系列，支持深度思考（`thinking={ type: "enabled" }`，当开启时，为强制深度思考。
* 更卓越的代码性能和先进的推理能力。

## 迁移清单（Checklist）

* [ ] 更新模型编码为 `glm-4.7`
* [ ] 采样参数：`temperature` 默认值 `1.0`, `top_p` 默认值 `0.95`，建议只选一个进行调参
* [ ] 深度思考：按需关闭或启用 `thinking={ type: "enabled" }`，用于复杂推理/编码
* [ ] 流式响应：启用 `stream=true` 并正确处理 `delta.reasoning_content` 与 `delta.content`
* [ ] 流式工具调用：启用 `stream=true` 和 `tool_stream=true` 并流式拼接 `delta.tool_calls[*].function.arguments`
* [ ] 最大输出与上下文：合理设置 `max_tokens`（GLM-4.7 最大输出 128K，上下文 200K）
* [ ] Prompt 优化：配合深度思考，采用更明确的指令与约束
* [ ] 开发环境验证：进行用例测试与回归，关注随机性、延迟、工具流中的参数完整性

## 开始迁移

### 1. 更新模型编码

* 将 `model` 更新为 `glm-4.7`。

```python  theme={null}
resp = client.chat.completions.create(
    model="glm-4.7",
    messages=[{"role": "user", "content": "简述 GLM-4.7 的优势"}]
)
```

### 2. 更新采样参数

* `temperature`：控制随机性；数值更高更发散，数值更低更稳定。
* `top_p`：控制核采样；更高值扩大候选集，更低值收敛候选集。
* `temperature` 默认为 `1.0`, `top_p` 默认为 `0.95`, 不建议同时调整两者。

```python  theme={null}
# Plan A：使用 temperature（推荐）
resp = client.chat.completions.create(
    model="glm-4.7",
    messages=[{"role": "user", "content": "写一段更具创意的品牌介绍"}],
    temperature=1.0
)

# Plan B：使用 top_p
resp = client.chat.completions.create(
    model="glm-4.7",
    messages=[{"role": "user", "content": "生成更稳定的技术说明"}],
    top_p=0.8
)
```

### 3. 深度思考（可选）

* GLM-4.7 延续支持深度思考能力，默认为开启。
* 在复杂推理、编码任务中，建议开启：

```python  theme={null}
resp = client.chat.completions.create(
    model="glm-4.7",
    messages=[{"role": "user", "content": "为我设计一个三层微服务架构"}],
    thinking={"type": "enabled"}
)
```

### 4. 流式输出与流式工具调用（可选）

* GLM-4.7 支持工具调用过程的实时流式构建与输出，默认 `False` 关闭，需同时打开：
  * `stream=True`：开启响应的流式输出
  * `tool_stream=True`：开启工具调用参数的流式输出

```python  theme={null}
response = client.chat.completions.create(
    model="glm-4.7",
    messages=[{"role": "user", "content": "北京天气怎么样"}],
    tools=[
        {
            "type": "function",
            "function": {
                "name": "get_weather",
                "description": "获取指定地点当前的天气情况",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": {"type": "string", "description": "城市，例如：北京、上海"},
                        "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
                    },
                    "required": ["location"]
                }
            }
        }
    ],
    stream=True,
    tool_stream=True,
)

# 初始化流式收集变量
reasoning_content = ""
content = ""
final_tool_calls = {}
reasoning_started = False
content_started = False

# 处理流式响应
for chunk in response:
    if not chunk.choices:
        continue

    delta = chunk.choices[0].delta

    # 流式推理过程输出
    if hasattr(delta, 'reasoning_content') and delta.reasoning_content:
        if not reasoning_started and delta.reasoning_content.strip():
            print("\n🧠 思考过程：")
            reasoning_started = True
        reasoning_content += delta.reasoning_content
        print(delta.reasoning_content, end="", flush=True)

    # 流式回答内容输出
    if hasattr(delta, 'content') and delta.content:
        if not content_started and delta.content.strip():
            print("\n\n💬 回答内容：")
            content_started = True
        content += delta.content
        print(delta.content, end="", flush=True)

    # 流式工具调用信息（参数拼接）
    if delta.tool_calls:
        for tool_call in delta.tool_calls:
            idx = tool_call.index
            if idx not in final_tool_calls:
                final_tool_calls[idx] = tool_call
                final_tool_calls[idx].function.arguments = tool_call.function.arguments
            else:
                final_tool_calls[idx].function.arguments += tool_call.function.arguments

# 输出最终的工具调用信息
if final_tool_calls:
    print("\n📋 命中 Function Calls :")
    for idx, tool_call in final_tool_calls.items():
        print(f"  {idx}: 函数名: {tool_call.function.name}, 参数: {tool_call.function.arguments}")
```

详见：[工具流式输出文档](/cn/guide/capabilities/stream-tool)

### 5. 测试与回归

> 在开发环境中先行验证迁移后的调用是否稳定，关注：

* 响应是否符合预期、是否出现过度随机或过度保守的输出
* 工具流式构建与输出是否正常
* 长上下文与深度思考场景下的延迟与成本

## 更多资源

<CardGroup cols={2}>
  <Card title="核心参数" icon={<svg style={{maskImage: "url(/resource/icon/star.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="/cn/guide/start/concept-param">
    模型常见参数概念与采样建议
  </Card>

  <Card title="工具流式输出" icon={<svg style={{maskImage: "url(/resource/icon/code.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="/cn/guide/capabilities/stream-tool">
    查看工具流式输出使用详情
  </Card>

  <Card title="API 参考" icon={<svg style={{maskImage: "url(/resource/icon/book.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="/cn/api/introduction">
    查看完整的 API 文档
  </Card>

  <Card title="技术支持" icon={<svg style={{maskImage: "url(/resource/icon/headset.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"}/>} href="https://bigmodel.cn/online-book/customerService">
    获取技术支持和帮助
  </Card>
</CardGroup>






> ## Documentation Index
> Fetch the complete documentation index at: https://docs.bigmodel.cn/llms.txt
> Use this file to discover all available pages before exploring further.

# GLM-4.7

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/rectangle-list.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 概览 </div>

GLM-4.7 系列是智谱最新旗舰模型，面向 **Agentic Coding** 场景强化了编码能力、长程任务规划与工具协同，并在多个公开基准的当期榜单中取得开源模型中的出色表现。通用能力提升，回复更简洁自然，写作更具沉浸感。在执行复杂智能体任务，在工具调用时指令遵循更强，Artifacts 与 Agentic Coding 的前端美感和长程任务完成效率进一步提升。

<Tabs>
  <Tab title="GLM-4.7">
    <CardGroup cols={3}>
      <Card title="定位" icon={<svg style={{maskImage: "url(/resource/icon/rocket.svg)", WebkitMaskImage: "url(/resource/icon/rocket.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        旗舰版
      </Card>

      <Card title="输入模态" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-right.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-right.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        文本
      </Card>

      <Card title="输出模态" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-left.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-left.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        文本
      </Card>

      <Card title="上下文窗口" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-arrow-up.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-arrow-up.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        200K
      </Card>

      <Card title="最大输出 Tokens" icon={<svg style={{maskImage: "url(/resource/icon/maximize.svg)", WebkitMaskImage: "url(/resource/icon/maximize.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        128K
      </Card>
    </CardGroup>
  </Tab>

  <Tab title="GLM-4.7-FlashX">
    <CardGroup cols={3}>
      <Card title="定位" icon={<svg style={{maskImage: "url(/resource/icon/rocket.svg)", WebkitMaskImage: "url(/resource/icon/rocket.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        轻量高速版
      </Card>

      <Card title="输入模态" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-right.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-right.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        文本
      </Card>

      <Card title="输出模态" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-left.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-left.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        文本
      </Card>

      <Card title="上下文窗口" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-arrow-up.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-arrow-up.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        200K
      </Card>

      <Card title="最大输出 Tokens" icon={<svg style={{maskImage: "url(/resource/icon/maximize.svg)", WebkitMaskImage: "url(/resource/icon/maximize.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        128K
      </Card>
    </CardGroup>
  </Tab>
</Tabs>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/bolt.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 能力支持 </div>

<CardGroup cols={3}>
  <Card title="思考模式" icon={<svg style={{maskImage: "url(/resource/icon/brain.svg)", WebkitMaskImage: "url(/resource/icon/brain.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />} href="/cn/guide/capabilities/thinking-mode">
    提供多种思考模式，覆盖不同任务需求
  </Card>

  <Card title="流式输出" icon={<svg style={{maskImage: "url(/resource/icon/maximize.svg)", WebkitMaskImage: "url(/resource/icon/maximize.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />} href="/cn/guide/capabilities/streaming">
    支持实时流式响应，提升用户交互体验
  </Card>

  <Card title="Function Call" icon={<svg style={{maskImage: "url(/resource/icon/function.svg)", WebkitMaskImage: "url(/resource/icon/function.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />} href="/cn/guide/capabilities/function-calling">
    强大的工具调用能力，支持多种外部工具集成
  </Card>

  <Card title="上下文缓存" icon={<svg style={{maskImage: "url(/resource/icon/database.svg)", WebkitMaskImage: "url(/resource/icon/database.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />} href="/cn/guide/capabilities/cache">
    智能缓存机制，优化长对话性能
  </Card>

  <Card title="结构化输出" icon={<svg style={{maskImage: "url(/resource/icon/code.svg)", WebkitMaskImage: "url(/resource/icon/code.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />} href="/cn/guide/capabilities/struct-output">
    支持 JSON 等结构化格式输出，便于系统集成
  </Card>

  <Card title="MCP" icon={<svg style={{maskImage: "url(/resource/icon/box.svg)", WebkitMaskImage: "url(/resource/icon/box.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    可灵活调用外部 MCP 工具与数据源，扩展应用场景
  </Card>
</CardGroup>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/stars.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 推荐场景 </div>

<AccordionGroup>
  <Accordion title="Agentic Coding">
    GLM-4.7 面向「任务完成」而非单点代码生成，能够从目标描述出发，自主完成需求理解、方案拆解与多技术栈整合。在包含前后端联动、实时交互与外设调用的复杂场景中，可直接生成结构完整、可运行的代码框架，显著减少人工拼装与反复调试成本，适合复杂 Demo、原型验证与自动化开发流程。
  </Accordion>

  <Accordion title="多模态交互与实时应用开发">
    在需要摄像头、实时输入与交互控制的场景中，GLM-4.7 展现出更强的系统级理解能力。能够将视觉识别、逻辑控制与应用代码整合为统一方案，支持如手势控制、实时反馈等交互式应用的快速构建，加速从想法到可运行应用的落地过程。
  </Accordion>

  <Accordion title="前端视觉审美优化">
    对视觉代码与 UI 规范的理解显著增强。GLM-4.7 能在布局结构、配色和谐度与组件样式上给出更具美感且一致的默认方案，减少样式反复“微调”的时间成本，适合低代码平台、AI 前端生成工具及快速原型设计场景。
  </Accordion>

  <Accordion title="高质量对话与复杂问题协作">
    在多轮对话中更稳定地保持上下文与约束条件，对简单问题回应更直接，对复杂问题能够持续澄清目标并推进解决路径。GLM-4.7 更像一名可协作的“问题解决型伙伴”，适用于开发支持、方案讨论与决策辅助等高频协作场景。
  </Accordion>

  <Accordion title="沉浸式写作与角色驱动创作">
    文字表达更细腻、更具画面感，能够通过气味、声音、光影等感官细节构建氛围。在角色扮演与叙事创作中，对世界观与人设的遵循更加稳定，剧情推进自然有张力，适合互动叙事、IP 内容创作与角色型应用。
  </Accordion>

  <Accordion title="专业级 PPT / 海报生成">
    在办公创作中，GLM-4.7 的版式遵循与审美稳定性明显提升。能够稳定适配 16:9 等主流比例，在字体层级、留白与配色上减少模板感，生成结果更接近“即用级”，适合 AI 演示工具、企业办公系统与自动化内容生成场景。
  </Accordion>

  <Accordion title="智能搜索与 Deep Research">
    强化用户意图理解、信息检索与结果融合能力。在复杂问题与研究型任务中，GLM-4.7 不仅返回信息，还能进行结构化整理与跨来源整合，通过多轮交互持续逼近核心结论，适合深度研究与决策支持场景。
  </Accordion>
</AccordionGroup>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/stars.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 详细介绍 </div>

<Steps>
  <Step title="Coding 能力全面提升" stepNumber={1} titleSize="h3">
    GLM-4.7 在编程、推理与智能体三个维度实现了显著突破：

    * **更强的编程能力**：显著提升了模型在多语言编码和在终端智能体中的效果；GLM-4.7 现在可以在 Claude Code、Kilo Code、TRAE、Cline 和 Roo Code 等编程框架中实现“先思考、再行动”的机制，在复杂任务上有更稳定的表现
    * **前端审美提升**：GLM-4.7 在前端生成质量方面明显进步，能够生成观感更佳的网页、PPT 、海报
    * **更强的工具调用能力**：GLM-4.7 提升了工具调用能力，在 BrowseComp 网页任务评测中获得 67 分；在 τ²-Bench 交互式工具调用评测中实现 84.7 分的开源 SOTA，超过 Claude Sonnet 4.5
    * **推理能力提升**：显著提升了数学和推理能力，在 HLE（"人类最后的考试"）基准测试中获得 42.8% 的成绩，较 GLM-4.6 提升 41%，超过 GPT-5.1
    * **通用能力增强**：GLM-4.7 对话更简洁智能且富有人情味，写作与角色扮演更具文采与沉浸感

    ![Description](https://cdn.bigmodel.cn/markdown/1766458923834image.png?attname=image.png)
    *`Code Arena`：全球百万用户参与盲测的专业编码评估系统，GLM-4.7 位列开源第一、国产第一，超过 GPT-5.2*

    在主流基准测试表现中，GLM-4.7 的代码能力对齐 Claude Sonnet 4.5：在 SWE-bench-Verified 获得开源第一；在 LiveCodeBench V6 达到 84.9 的开源 SOTA 分数，超过 Claude Sonnet 4.5；在 SWE-bench Verified达到 73.8%（相较 GLM-4.6 提升 5.8%），SWE-bench Multilingual 达到 66.7%（提升 12.9%），Terminal Bench 2.0 达到 41%（提升 16.5%）。

    ![Description](https://cdn.bigmodel.cn/markdown/1766459089466image.png?attname=image.png)
  </Step>

  <Step title="真实编程场景下的体感提升" stepNumber={2} titleSize="h3">
    <Tabs>
      <Tab title="实际编程任务表现">
        在 Claude Code 环境中，我们对 100 个真实编程任务进行了测试，覆盖前端、后端与指令遵循等核心能力。结果显示，GLM-4.7 相较 GLM-4.6 在稳定性与可交付性上均有明显提升。
        ![Description](https://cdn.bigmodel.cn/markdown/1766418822788image.png?attname=image.png)
        随着编程能力的增强，开发者可以更自然地以“任务交付”为核心组织开发流程，形成从需求理解到落地实现的端到端闭环。
      </Tab>

      <Tab title="思考能力的可控进化">
        GLM-4.7 进一步强化了 GLM-4.5 以来就支持的交错式思考能力，引入保留式思考与轮级思考，使复杂任务执行更稳、更可控。

        * 交错式思考：每次回答/工具调用前都会思考，提升复杂指令的遵循能力和代码生成质量。
        * 保留式思考：多轮对话中自动保留思考块，提升缓存命中率，降低成本，适合长程复杂任务。
        * 轮级思考：支持在同一会话内按“轮”控制推理开销——简单任务可关闭思考以降低时延，复杂任务可开启思考以提升准确性与稳定性。

        *相关参考文档：[https://docs.bigmodel.cn/cn/guide/capabilities/thinking-mode](https://docs.bigmodel.cn/cn/guide/capabilities/thinking-mode)*
      </Tab>

      <Tab title="综合任务执行能力">
        GLM-4.7 在复杂任务中展现出更强的任务拆解与技术栈整合能力，能够一次性给出**完整、可运行的代码**，并明确关键依赖与运行步骤，显著减少人工调试成本。

        <video className="m-0 p-1" src="https://cdn.bigmodel.cn/static/glm4.7/游戏CASE（中文）-1222.mp4" controls />

        案例展示由 GLM-4.7 独立完成的高交互小游戏，如植物大战僵尸、水果忍者。
      </Tab>

      <Tab title="前端审美提升">
        GLM-4.7 增强了对视觉代码的理解。在前端设计中，它能更好地理解 UI 设计规范，在布局结构、配色和谐度及组件样式上提供更具美感的默认方案，从而减少开发者在样式“微调”上花费的时间。

        <video className="m-0 p-1" src="https://cdn.bigmodel.cn/static/glm4.7/网页CASE（中文）-1222.mp4" controls />

        GLM-4.7 在办公创作中版式与审美显著升级，PPT 16:9 适配率从52%跃升至 91%，生成结果基本“即开即用”；海报设计的排版与配色更加灵活，具备设计感。

        <video className="m-0 p-1" src="https://cdn.bigmodel.cn/static/glm4.7/PPT+海报CASE（中文）-1222.mp4" controls />
      </Tab>
    </Tabs>
  </Step>
</Steps>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/gauge-high.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 使用资源 </div>

[体验中心](https://bigmodel.cn/trialcenter/modeltrial/text?modelCode=glm-4.7)：快速测试模型在业务场景上的效果<br />
[接口文档](/api-reference/%E6%A8%A1%E5%9E%8B-api/%E5%AF%B9%E8%AF%9D%E8%A1%A5%E5%85%A8)：API 调用方式

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/rectangle-code.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 调用示例 </div>

以下是完整的调用示例，帮助您快速上手 GLM-4.7 模型。

<Tabs>
  <Tab title="cURL">
    **基础调用**

    ```bash  theme={null}
    curl -X POST "https://open.bigmodel.cn/api/paas/v4/chat/completions" \
        -H "Content-Type: application/json" \
        -H "Authorization: Bearer your-api-key" \
        -d '{
            "model": "glm-4.7",
            "messages": [
            {
                "role": "user",
                "content": "作为一名营销专家，请为我的产品创作一个吸引人的口号"
            },
            {
                "role": "assistant",
                "content": "当然，要创作一个吸引人的口号，请告诉我一些关于您产品的信息"
            },
            {
                "role": "user",
                "content": "智谱AI 开放平台"
            }
            ],
            "thinking": {
                "type": "enabled"
            },
            "max_tokens": 65536,
            "temperature": 1.0
        }'
    ```

    **流式调用**

    ```bash  theme={null}
    curl -X POST "https://open.bigmodel.cn/api/paas/v4/chat/completions" \
        -H "Content-Type: application/json" \
        -H "Authorization: Bearer your-api-key" \
        -d '{
            "model": "glm-4.7",
            "messages": [
            {
                "role": "user",
                "content": "作为一名营销专家，请为我的产品创作一个吸引人的口号"
            },
            {
                "role": "assistant",
                "content": "当然，要创作一个吸引人的口号，请告诉我一些关于您产品的信息"
            },
            {
                "role": "user",
                "content": "智谱AI开放平台"
            }
            ],
            "thinking": {
                "type": "enabled"
            },
            "stream": true,
            "max_tokens": 65536,
            "temperature": 1.0
        }'
    ```
  </Tab>

  <Tab title="Python">
    **安装 SDK**

    ```bash  theme={null}
    # 安装最新版本
    pip install zai-sdk
    # 或指定版本
    pip install zai-sdk==0.2.2
    ```

    **验证安装**

    ```python  theme={null}
    import zai
    print(zai.__version__)
    ```

    **基础调用**

    ```python  theme={null}
    from zai import ZhipuAiClient

    client = ZhipuAiClient(api_key="your-api-key")  # 请填写您自己的 API Key

    response = client.chat.completions.create(
        model="glm-4.7",
        messages=[
            {"role": "user", "content": "作为一名营销专家，请为我的产品创作一个吸引人的口号"},
            {"role": "assistant", "content": "当然，要创作一个吸引人的口号，请告诉我一些关于您产品的信息"},
            {"role": "user", "content": "智谱AI开放平台"}
        ],
        thinking={
            "type": "enabled",    # 启用深度思考模式
        },
        max_tokens=65536,          # 最大输出 tokens
        temperature=1.0           # 控制输出的随机性
    )

    # 获取完整回复
    print(response.choices[0].message)
    ```

    **流式调用**

    ```python  theme={null}
    from zai import ZhipuAiClient

    client = ZhipuAiClient(api_key="your-api-key")  # 请填写您自己的 API Key

    response = client.chat.completions.create(
        model="glm-4.7",
        messages=[
            {"role": "user", "content": "作为一名营销专家，请为我的产品创作一个吸引人的口号"},
            {"role": "assistant", "content": "当然，要创作一个吸引人的口号，请告诉我一些关于您产品的信息"},
            {"role": "user", "content": "智谱AI开放平台"}
        ],
        thinking={
            "type": "enabled",    # 启用深度思考模式
        },
        stream=True,              # 启用流式输出
        max_tokens=65536,          # 最大输出tokens
        temperature=1.0           # 控制输出的随机性
    )

    # 流式获取回复
    for chunk in response:
        if chunk.choices[0].delta.reasoning_content:
            print(chunk.choices[0].delta.reasoning_content, end='', flush=True)

        if chunk.choices[0].delta.content:
            print(chunk.choices[0].delta.content, end='', flush=True)
    ```
  </Tab>

  <Tab title="Java">
    **安装 SDK**

    **Maven**

    ```xml  theme={null}
    <dependency>
        <groupId>ai.z.openapi</groupId>
        <artifactId>zai-sdk</artifactId>
        <version>0.3.3</version>
    </dependency>
    ```

    **Gradle (Groovy)**

    ```groovy  theme={null}
    implementation 'ai.z.openapi:zai-sdk:0.3.3'
    ```

    **基础调用**

    ```java  theme={null}
    import ai.z.openapi.ZhipuAiClient;
    import ai.z.openapi.service.model.ChatCompletionCreateParams;
    import ai.z.openapi.service.model.ChatCompletionResponse;
    import ai.z.openapi.service.model.ChatMessage;
    import ai.z.openapi.service.model.ChatMessageRole;
    import ai.z.openapi.service.model.ChatThinking;
    import java.util.Arrays;

    public class BasicChat {
        public static void main(String[] args) {
            // 初始化客户端
            ZhipuAiClient client = ZhipuAiClient.builder().ofZHIPU()
                .apiKey("your-api-key")
                .build();

            // 创建聊天完成请求
            ChatCompletionCreateParams request = ChatCompletionCreateParams.builder()
                .model("glm-4.7")
                .messages(Arrays.asList(
                    ChatMessage.builder()
                        .role(ChatMessageRole.USER.value())
                        .content("作为一名营销专家，请为我的产品创作一个吸引人的口号")
                        .build(),
                    ChatMessage.builder()
                        .role(ChatMessageRole.ASSISTANT.value())
                        .content("当然，要创作一个吸引人的口号，请告诉我一些关于您产品的信息")
                        .build(),
                    ChatMessage.builder()
                        .role(ChatMessageRole.USER.value())
                        .content("智谱AI开放平台")
                        .build()
                ))
                .thinking(ChatThinking.builder().type("enabled").build())
                .maxTokens(65536)
                .temperature(1.0f)
                .build();

            // 发送请求
            ChatCompletionResponse response = client.chat().createChatCompletion(request);

            // 获取回复
            if (response.isSuccess()) {
                Object reply = response.getData().getChoices().get(0).getMessage();
                System.out.println("AI 回复: " + reply);
            } else {
                System.err.println("错误: " + response.getMsg());
            }
        }
    }
    ```

    **流式调用**

    ```java  theme={null}
    import ai.z.openapi.ZhipuAiClient;
    import ai.z.openapi.service.model.ChatCompletionCreateParams;
    import ai.z.openapi.service.model.ChatCompletionResponse;
    import ai.z.openapi.service.model.ChatMessage;
    import ai.z.openapi.service.model.ChatMessageRole;
    import ai.z.openapi.service.model.ChatThinking;
    import ai.z.openapi.service.model.Delta;
    import java.util.Arrays;

    public class StreamingChat {
        public static void main(String[] args) {
            // 初始化客户端
            ZhipuAiClient client = ZhipuAiClient.builder().ofZHIPU()
                .apiKey("your-api-key")
                .build();

            // 创建流式聊天完成请求
            ChatCompletionCreateParams request = ChatCompletionCreateParams.builder()
                .model("glm-4.7")
                .messages(Arrays.asList(
                    ChatMessage.builder()
                        .role(ChatMessageRole.USER.value())
                        .content("作为一名营销专家，请为我的产品创作一个吸引人的口号")
                        .build(),
                    ChatMessage.builder()
                        .role(ChatMessageRole.ASSISTANT.value())
                        .content("当然，要创作一个吸引人的口号，请告诉我一些关于您产品的信息")
                        .build(),
                    ChatMessage.builder()
                        .role(ChatMessageRole.USER.value())
                        .content("智谱AI开放平台")
                        .build()
                ))
                .thinking(ChatThinking.builder().type("enabled").build())
                .stream(true)  // 启用流式输出
                .maxTokens(65536)
                .temperature(1.0f)
                .build();

            ChatCompletionResponse response = client.chat().createChatCompletion(request);

            if (response.isSuccess()) {
                response.getFlowable().subscribe(
                    // Process streaming message data
                    data -> {
                        if (data.getChoices() != null && !data.getChoices().isEmpty()) {
                            Delta delta = data.getChoices().get(0).getDelta();
                            System.out.print(delta + "\n");
                        }
                    },
                    // Process streaming response error
                    error -> System.err.println("\nStream error: " + error.getMessage()),
                    // Process streaming response completion event
                    () -> System.out.println("\nStreaming response completed")
                );
            } else {
                System.err.println("Error: " + response.getMsg());
            }
        }
    }
    ```
  </Tab>

  <Tab title="Python(旧)">
    **更新 SDK 至 2.1.5.20250726**

    ```bash  theme={null}
    # 安装最新版本
    pip install zhipuai

    # 或指定版本
    pip install zhipuai==2.1.5.20250726
    ```

    **基础调用**

    ```python  theme={null}
    from zhipuai import ZhipuAI

    client = ZhipuAI(api_key="your-api-key")  # 请填写您自己的 API Key

    response = client.chat.completions.create(
      model="glm-4.7",
      messages=[
          {"role": "user", "content": "作为一名营销专家，请为我的产品创作一个吸引人的口号"},
          {"role": "assistant", "content": "当然，要创作一个吸引人的口号，请告诉我一些关于您产品的信息"},
          {"role": "user", "content": "智谱AI开放平台"}
      ],
      thinking={
        "type": "enabled",
      },
      max_tokens=65536,
      temperature=1.0
    )

    # 获取完整回复
    print(response.choices[0].message)
    ```

    **流式调用**

    ```python  theme={null}
    from zhipuai import ZhipuAI

    client = ZhipuAI(api_key="your-api-key")  # 请填写您自己的 API Key

    response = client.chat.completions.create(
      model="glm-4.7",
      messages=[
          {"role": "user", "content": "作为一名营销专家，请为我的产品创作一个吸引人的口号"},
          {"role": "assistant", "content": "当然，要创作一个吸引人的口号，请告诉我一些关于您产品的信息"},
          {"role": "user", "content": "智谱AI开放平台"}
      ],
      thinking={
        "type": "enabled",
      },
      stream=True,              # 启用流式输出
      max_tokens=65536,
      temperature=1.0
    )

    # 流式获取回复
    for chunk in response:
        if chunk.choices[0].delta.reasoning_content:
            print(chunk.choices[0].delta.reasoning_content, end='', flush=True)

        if chunk.choices[0].delta.content:
            print(chunk.choices[0].delta.content, end='', flush=True)
    ```
  </Tab>
</Tabs>










> ## Documentation Index
> Fetch the complete documentation index at: https://docs.bigmodel.cn/llms.txt
> Use this file to discover all available pages before exploring further.

# GLM-OCR

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/rectangle-list.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 概览 </div>

GLM-OCR  是一款轻量级的专业 OCR 模型，参数仅为0.9B，但多项能力达到了SOTA水平，以 “小尺寸、高精度” 实现文档解析能力新标杆。其核心要点如下：

* **性能 SOTA**：在模型发布时以 94.62 分登顶 OmniDocBench V1.5，并在表格、公式等多项主流文档理解基准中取得当前最佳表现；
* **针对真实业务场景优化**：在代码文档、复杂表格、印章等复杂场景中表现稳定且精度领先，即使在版式复杂、字体多样或图文混排情况下，识别准确度依旧出色；
* **高效高性价比**：仅 0.9B 参数规模，支持 VLLM 和 SGLang 部署，显著降低推理延迟与算力开销,成本约为传统 OCR 方案的 1/10。

<CardGroup cols={3}>
  <Card title="输入模态" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-right.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-right.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    - PDF、图片（JPG、PNG）
    - 单图 ≤ 10 MB，PDF ≤ 50 MB
    - 最大支持 100 页
  </Card>

  <Card title="输出模态" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-left.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-left.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    文本、图片链接、md 文档
  </Card>

  <Card title="支持的语言" icon={<svg style={{maskImage: "url(/resource/icon/brain.svg)", WebkitMaskImage: "url(/resource/icon/brain.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    中文、英文、法语、西班牙语、俄罗斯语、德语、日语、韩语等……
  </Card>
</CardGroup>

<Tip>
  GLM-OCR 价格详情请前往[价格界面](https://open.bigmodel.cn/pricing)
</Tip>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/bolt.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 能力支持 </div>

<CardGroup cols={3}>
  <Card title="结构化输出" href="/cn/guide/capabilities/struct-output" icon={<svg style={{maskImage: "url(/resource/icon/maximize.svg)", WebkitMaskImage: "url(/resource/icon/maximize.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    返回符合预定义格式的 JSON 数据
  </Card>

  <Card title="文档解析" icon={<svg style={{maskImage: "url(/resource/icon/eye.svg)", WebkitMaskImage: "url(/resource/icon/eye.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    高精度的文档信息识别能力
  </Card>
</CardGroup>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/stars.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 推荐场景 </div>

<AccordionGroup>
  <Accordion title="通用文本识别" defaultOpen="true">
    GLM-OCR 支持照片、截图、扫描件、文档输入，能够识别手写体、印章、代码等特殊文字，可广泛应用于教育、科研、办公等场景。
  </Accordion>

  <Accordion title="复杂表格解析">
    针对合并单元格、多层表头等复杂结构，模型能精准理解并直接输出 HTML 代码。无需二次制表，识别结果即可用于网页展示或数据处理，大幅提升表格录入与转换效率。
  </Accordion>

  <Accordion title="信息结构化提取">
    GLM-OCR 可从各类卡证、票据、表格中智能提取关键字段，并输出标准的 JSON 格式，无缝对接银行、保险、政务及物流等行业系统。
  </Accordion>

  <Accordion title="批量处理与RAG支持">
    GLM-OCR 支持大批量文档的识别与解析，其高精度的识别能力和规整的输出格式，可为检索增强生成（RAG）提供坚实基础。
  </Accordion>
</AccordionGroup>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/arrow-up.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 详细介绍 </div>

<Steps>
  <Step title="性能SOTA、精准干活儿" stepNumber={1} titleSize="h3">
    得益于自研 CogViT 视觉编码器与深度场景优化，GLM-OCR 实现了“小尺寸，高精度”。
    GLM-OCR 参数量仅 0.9B，但模型发布时在权威文档解析榜单 OmniDocBench V1.5 中以 94.6 分取得SOTA。在文本、公式、表格识别及信息抽取四大细分领域的表现优于多款OCR专项模型，性能接近 Gemini-3-Pro 。

    ![Description](https://cdn.bigmodel.cn/markdown/1770049137241img_v3_02uh_8e984807-871e-45eb-8ea2-706fb275cf3g.png?attname=img_v3_02uh_8e984807-871e-45eb-8ea2-706fb275cf3g.png)

    除了公开榜单，我们还针对真实业务中的六大核心场景进行了内部测评。结果显示，在模型发布时GLM-OCR 在代码文档、真实场景表格、手写体、多语言、印章识别、票据提取等维度均取得显著优势。

    ![Description](https://cdn.bigmodel.cn/markdown/1770049153590img_v3_02uh_b3aff49e-f980-4bf4-9dfb-20c7bbce04bg.png?attname=img_v3_02uh_b3aff49e-f980-4bf4-9dfb-20c7bbce04bg.png)
  </Step>

  <Step title="更快、更便宜" stepNumber={2} titleSize="h3">
    速度方面，我们对比了在相同硬件环境与测试条件下（单副本，单并发），分别以图像文件和 PDF 文件为输入，不同 OCR 方法完成解析并导出 Markdown 文件的速度差异。结果显示，GLM-OCR 处理 PDF 文档的吞吐量达 1.86 页/秒，图片达 0.67 张/秒，速度显著优于同类模型。

    ![Description](https://cdn.bigmodel.cn/markdown/1770038561894img_v3_02uh_e883d08f-9ebf-4438-90e0-ab741438ff6g.png?attname=img_v3_02uh_e883d08f-9ebf-4438-90e0-ab741438ff6g.png)

    价格方面，API输入输出同价，仅需 0.2元/百万Tokens。1 元即可处理约 2000 张 A4 大小扫描图片或 200 份 10 页简单排版PDF，成本约为传统 OCR 方案的 1/10。
  </Step>
</Steps>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/ballot.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 应用示例 </div>

<Tabs>
  <Tab title="手写字识别">
    <CardGroup cols={2}>
      <Card title="输入" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-right.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-right.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        ![Description](https://cdn.bigmodel.cn/markdown/1770033643596image.png?attname=image.png)<br />
      </Card>

      <Card title="输出" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-left.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-left.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        六国灭亡了，天下统一了，蜀地的山秃了，阿房宫建成了。 它覆盖三百多里地，遮蔽天日。阿房宫从骊山北边建起，折而向西，一直通向咸阳。
      </Card>
    </CardGroup>
  </Tab>

  <Tab title="表格识别">
    <CardGroup cols={2}>
      <Card title="输入" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-right.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-right.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        ![Description](https://cdn.bigmodel.cn/markdown/1770033857500image.png?attname=image.png)
      </Card>

      <Card title="输出" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-left.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-left.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        ![Description](https://cdn.bigmodel.cn/markdown/1770033891518image.png?attname=image.png)
      </Card>
    </CardGroup>
  </Tab>

  <Tab title="信息结构化提取">
    <CardGroup cols={2}>
      <Card title="输入" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-right.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-right.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        ![Description](https://cdn.bigmodel.cn/markdown/1770033970153image.png?attname=image.png)
        **prompt**

        请按下列JSON格式输出图中信息:

        ```bash  theme={null}
        {
            "标题": "",
            "发票号码": "",
            "开票日期": {
            "年": "",
            "月": "",
            "日": ""
        },
            "购买方信息": {
            "名称": "",
            "统一社会信用代码/纳税人识别号": ""
        },
            "销售方信息": {
            "名称": "",
            "统一社会信用代码/纳税人识别号": ""
        },
            "项目名称": "",
            "单价": "",
            "数量": "",
            "金额": "",
            "税率/征收率": "",
            "税额": "",
            "金额合计": "",
            "税额合计": "",
            "出行人": "",
            "有效身份证件号": "",
            "出行日期": "",
            "出发地": "",
            "到达地": "",
            "等级": "",
            "交通工具类型": "",
            "价税合计（大写）": "",
            "价税合计（小写）": "",
            "备注": "",
            "开票人": "",
            "印章": []
        }
        ```
      </Card>

      <Card title="输出" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-left.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-left.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        ```bush  theme={null}
        {
            "标题": "电子发票（普通发票）",
            "发票号码": "25127000000102638675",
            "开票日期": {
            "年": "2025",
            "月": "04",
            "日": "08"
        },
            "购买方信息": {
            "名称": "深圳市百川数安科技有限公司",
            "统一社会信用代码/纳税人识别号": "91440300MA5GUFD LXF"
        },
            "销售方信息": {
            "名称": "天津鞍马出行科技有限公司",
            "统一社会信用代码/纳税人识别号": "91120106MACB2BWC1M"
        },
            "项目名称": "*运输服务*客运服务费",
            "单价": "8.74",
            "数量": "1",
            "金额": "8.74",
            "税率/征收率": "3%",
            "税额": "0.26",
            "金额合计": "¥8.74",
            "税额合计": "¥0.26",
            "出行人": "",
            "有效身份证件号": "",
            "出行日期": "",
            "出发地": "",
            "到达地": "",
            "等级": "",
            "交通工具类型": "",
            "价税合计（大写）": "⊗玖圆整",
            "价税合计（小写）": "¥9.00",
            "备注": "",
            "开票人": "刘薇",
            "印章": [
            "全国统一发票监制章\n国家税务总局\n天津市税务局"
            ]
        }
        ```
      </Card>
    </CardGroup>
  </Tab>
</Tabs>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/gauge-high.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 使用资源 </div>

[接口文档](/api-reference/%E6%A8%A1%E5%9E%8B-api/%E7%89%88%E9%9D%A2%E8%A7%A3%E6%9E%90)：API 调用方式

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/rectangle-code.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 调用示例 </div>

以下是完整的调用示例，帮助您快速上手 GLM-OCR 模型。

<Tabs>
  <Tab title="cURL">
    ```bash  theme={null}
    curl --location --request POST 'https://open.bigmodel.cn/api/paas/v4/layout_parsing' \
    --header 'Authorization: your_api_key' \
    --header 'Content-Type: application/json' \
    --data-raw '{
      "model": "glm-ocr",
      "file": "https://cdn.bigmodel.cn/static/logo/introduction.png"
    }'
    ```
  </Tab>

  <Tab title="Python">
    **安装 SDK**

    ```bash  theme={null}
    # 安装最新版本
    pip install zai-sdk
    # 或指定版本
    pip install zai-sdk==0.2.2
    ```

    **验证安装**

    ```python  theme={null}
    import zai
    print(zai.__version__)
    ```

    **基础调用**

    ```python  theme={null}
    from zai import ZhipuAiClient

    # 初始化客户端
    client = ZhipuAiClient(api_key="your-api-key")

    image_url = "https://cdn.bigmodel.cn/static/logo/introduction.png"

    # 调用布局解析 API
    response = client.layout_parsing.create(
        model="glm-ocr",
        file=image_url
    )

    # 输出结果
    print(response)
    ```
  </Tab>

  <Tab title="Java">
    **安装 SDK**

    **Maven**

    ```xml  theme={null}
    <dependency>
      <groupId>ai.z.openapi</groupId>
      <artifactId>zai-sdk</artifactId>
      <version>0.3.3</version>
    </dependency>
    ```

    **Gradle (Groovy)**

    ```groovy  theme={null}
    implementation 'ai.z.openapi:zai-sdk:0.3.3'
    ```

    **基础调用**

    ```java  theme={null}
    import ai.z.openapi.ZhipuAiClient;
    import ai.z.openapi.service.layoutparsing.LayoutParsingCreateParams;
    import ai.z.openapi.service.layoutparsing.LayoutParsingResponse;
    import ai.z.openapi.service.layoutparsing.LayoutParsingResult;

    public class LayoutParsing {
        public static void main(String[] args) {
            // 初始化客户端
            ZhipuAiClient client = ZhipuAiClient.builder()
                .ofZHIPU()
                .apiKey("your-api-key")
                .build();

            String model = "glm-ocr";
            String file = "https://cdn.bigmodel.cn/static/logo/introduction.png";

            // 创建布局解析请求
            LayoutParsingCreateParams params = LayoutParsingCreateParams.builder()
                .model(model)
                .file(file)
                .build();

            // 发送请求
            LayoutParsingResponse response = client.layoutParsing().layoutParsing(params);

            // 处理响应
            if (response.isSuccess()) {
                System.out.println("解析结果: " + response.getData());
            } else {
                System.err.println("错误: " + response.getMsg());
            }
        }
    }
    ```
  </Tab>
</Tabs>












> ## Documentation Index
> Fetch the complete documentation index at: https://docs.bigmodel.cn/llms.txt
> Use this file to discover all available pages before exploring further.

# GLM-Image

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/rectangle-list.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 概览 </div>

GLM-Image 是智谱新旗舰图像生成模型， 模型全程基于国产芯片完成训练，采用独创的「自回归+扩散解码器」混合架构，兼顾全局指令理解与局部细节刻画，克服了海报、PPT、科普图等知识密集型场景生成难题，是面向以 Nano Banana Pro 为代表的新一代「认知型生成」技术范式的一次重要探索。

<CardGroup cols={2}>
  <Card title="价格" icon={<svg style={{maskImage: "url(/resource/icon/coins.svg)", WebkitMaskImage: "url(/resource/icon/coins.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    0.1 元 / 次
  </Card>

  <Card title="输入模态" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-right.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-right.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    文本（最大输入1000字符）
  </Card>

  <Card title="输出模态" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-left.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-left.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    图像
  </Card>

  <Card title="多分辨率" icon={<svg style={{maskImage: "url(/resource/icon/images.svg)", WebkitMaskImage: "url(/resource/icon/images.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    支持 1:1、3:4、4:3、16:9 等
  </Card>
</CardGroup>

<Tip>
  **推荐常用尺寸：** 1280x1280 、 1568x1056 、 1056x1568 、 1472x1088 、 1088x1472 、 1728x960 、 960x1728。

  **自定义参数：** 长宽需在 512px-2048px 范围内，且长宽均需为32的整数倍。
</Tip>

<Info>
  请注意，GLM-Image 模型的输出是图片 URL，您需要通过 URL 下载图片。
</Info>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/stars.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 推荐场景 </div>

<AccordionGroup>
  <Accordion title="商业海报">
    能够生成构图完整、视觉层次清晰、整体设计感突出的节日海报与商业宣传图片，并支持文字内容的精准嵌入与稳定呈现，适用于品牌传播、市场推广等多种商业场景。
  </Accordion>

  <Accordion title="科普插画">
    更擅长绘制包含复杂逻辑关系、流程说明与文字注释的科普插画和原理示意图，能够在保证画面美观的同时，清晰、准确地传达知识结构与核心信息。
  </Accordion>

  <Accordion title="多格图画">
    在生成电商展示图、故事漫画等多格图画时，GLM-Image 可以有效保持整体画风与主体形象的一致性，同时显著提升多处文字生成的准确率，确保内容连贯、表达统一。
  </Accordion>

  <Accordion title="社交媒体图文">
    适用于制作封面设计与版式结构较为复杂的社交媒体图文内容，支持灵活排版与多样化表达，让创作过程更加高效，呈现效果更加丰富多元。
  </Accordion>
</AccordionGroup>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/gauge-high.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 使用资源 </div>

[体验中心](https://bigmodel.cn/trialcenter/modeltrial/image)：快速测试模型在业务场景上的效果<br />
[接口文档](/api-reference/%E6%A8%A1%E5%9E%8B-api/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90)：API 调用方式

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/arrow-up.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 详细介绍 </div>

<Steps>
  <Step title="架构创新：读懂指令，写对文字" titleSize="h3">
    **GLM-image是我们面向「认知型生成」技术范式的一次重要探索，** 这是首个开源的工业表现级离散自回归图像生成模型。

    GLM-Image 引入了「自回归+扩散解码器」混合架构，融合了 9B 的自回归模型与 7B 的 DiT 扩散解码器。前者利用其语言模型的底座优势，专注于提升对指令的语义理解和画面的全局构图；后者配合 Glyph Encoder 的文本编码器，专注于还原图像的高频细节和文字笔画，以此改善模型“提笔忘字”的现象。

    ![Description](https://cdn.bigmodel.cn/markdown/1768305506516image.png?attname=image.png)
    *general pipeline*

    ![Description](https://cdn.bigmodel.cn/markdown/1768305604344image.png?attname=image.png)
    *decoder formulation*
  </Step>

  <Step title="开源 SOTA：更擅长文字密集生成任务" stepNumber={2} titleSize="h3">
    基于上述架构创新，GLM-Image在文字渲染的权威榜单中达到开源 SOTA水平。

    ![Description](https://cdn.bigmodel.cn/markdown/1768308056990image.png?attname=image.png)

    * **CVTG-2K（复杂视觉文字生成）** 榜单核心考察模型在图像中同时生成多处文字的准确性。在多区域文字生成准确率上，GLM-Image 凭借 0.9116 的 Word Accuracy（文字准确率）成绩，位列开源模型前列。在NED（归一化编辑距离）指标上，GLM-Image 同样以 0.9557 胜出，表明其生成的文字与目标文字高度一致，错字、漏字情况更少。
    * **LongText-Bench（长文本渲染）** 榜单考察模型渲染长文本、多行文字的准确性，覆盖招牌、海报、PPT、对话框等8种文字密集场景，并分设中英双语测试，GLM-Image以英文0.9524、中文0.9788的成绩位列开源模型前列。
  </Step>

  <Step title="首个国产芯片训练出的 SOTA 多模态模型" stepNumber={3} titleSize="h3">
    GLM-Image 是我们对国产计算生态的一次深度探索与验证。从早期的数据预处理到最终的大规模预训练，模型构建的全流程均在昇腾Atlas 800T A2设备上完成。

    GLM-Image 是首个在国产芯片上完成全流程训练的SOTA多模态模型，验证了在国产全栈算力底座上训练高性能多模态生成模型的可行性。我们希望这一实践能为社区挖掘国产算力潜力提供有价值的参考。

    ![Description](https://cdn.bigmodel.cn/markdown/1768310696625image.png?attname=image.png)
  </Step>
</Steps>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/ballot.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 应用示例 </div>

<Tabs>
  <Tab title="科普插画">
    <CardGroup cols={2}>
      <Card title="Prompt" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-right.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-right.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        竖版手工剪贴簿风格的图像。顶部是一条亮红色粗糙撕裂边缘的纸质横幅，用半透明和纸胶带斜着固定，左上角夹着金色回形针，压着一小块写有「首发」的碎纸。横幅上用粗黑体手工剪报风写着主标题「GLM-Image 开源：国产芯片炼出图像生成 SOTA」，标题周围用黑色马克笔画着放射线和手绘画笔调色盘图标。
        背景是拼贴的AI生成图片碎片、芯片电路图纹理、水彩晕染和浅蓝色卡纸。左侧有一个带磨损金属边的数码相框，用透明胶带斜贴，相框内大字写着「自回归 + 扩散解码器」，副标题「9B 自回归理解指令 + 7B DiT 精绘细节」，背景是文字prompt气泡到精美图像的箭头连接图，边缘有手绘箭头标注「读懂指令」「写对文字」。
        右侧散落三张不同颜色的撕裂纸条便利贴，被和纸胶带交叉固定。配有芯片实物照片剪影加华为logo小贴纸、中文艺术字海报截图、多分辨率图像网格等插图。三个撕裂纸条标签带粗黑描边：「昇腾 A2 + 昇思 MindSpore：全程国产训练」「CVTG-2K & LongText-Bench：文字渲染开源第一」「384×384 到 2048×2048：任意比例原生支持」。旁边还有一条窄蓝色撕裂纸条写着「认知型生成：知识 + 推理新范式」，上面有马克笔波浪线和星星。
        底部是一整条深蓝色撕裂纸带，印着电路纹理，用和纸胶带固定。通栏大标题「从"画个图"到"懂你想要什么"的认知型生成引擎」
      </Card>

      <Card title="生成图片" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-left.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-left.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        ![Description](https://cdn.bigmodel.cn/markdown/176832067703920260113-235926.jpeg)
      </Card>
    </CardGroup>
  </Tab>

  <Tab title="高质量人像">
    <CardGroup cols={2}>
      <Card title="Prompt" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-right.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-right.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        哈苏胶片质感的画面中，一位长发美女置身于柔和的室内光影里，窗外的枝叶在微风中摇曳，将斑驳的树影投射到她的脸庞和肩头；薄纱轻轻垂落在背景，营造出朦胧唯美的氛围，轮廓光勾勒出她慵懒自然的姿态，凌乱的长发在风中轻轻飘起，发丝在阳光的照射下泛着微光；近景特写捕捉她深情凝望镜头的瞬间，清透细腻的肌肤在高曝光与高明暗的对比中展现丰富的质感，背景略微模糊，泛光与晕染交织出轻柔的梦幻效果，画面带有高噪点的胶片色彩与微妙的反射，整体细节生动，仿佛凝固在午后微风与光影交错的诗意瞬间。
      </Card>

      <Card title="生成图片" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-left.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-left.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        ![Description](https://cdn.bigmodel.cn/markdown/1768310904165image.png?attname=image.png)
      </Card>
    </CardGroup>
  </Tab>

  <Tab title="社交媒体图文">
    <CardGroup cols={2}>
      <Card title="Prompt" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-right.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-right.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        <br />

        冬季 OOTD 穿搭封面，复古拼贴风：主体是一位女生的主穿搭（浅蓝宽松毛衣 + 黄格衬衫内搭 + 酒红半裙 + 粉白花纹围巾 + 粉调手提包），周围拼贴 2-3 张同系列冬季搭配小图（如蓝羽绒服 + 黑阔腿裤、棕外套 + 藏青裤）；背景融合浅灰方格墙面 + 户外街景局部；添加大尺寸浅蓝艺术字 “OOTD”，手写风标注文字（如 “autumn/win”“work/date”），点缀星星、手绘箭头等小装饰，以及咖啡杯、播放键小图标；整体色调柔和温暖，元素错落排版，营造活泼的冬日穿搭参考感
      </Card>

      <Card title="生成图片" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-left.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-left.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        ![Description](https://cdn.bigmodel.cn/markdown/1768309855615image.png?attname=image.png)
      </Card>
    </CardGroup>
  </Tab>

  <Tab title="商业海报">
    <CardGroup cols={2}>
      <Card title="Prompt" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-right.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-right.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        <br />

        暗黑艺术感巴宝莉品牌宣传海报：整体采用低饱和深灰色暗调背景，配色以黑白（两匹马）+ 巴宝莉标志性红黑格纹（含白、浅棕线条）为主，文字与 logo 为白色；主体是两匹写实细腻质感的马（左侧纯白、右侧纯黑），头部均被巴宝莉经典红黑格纹丝巾蒙住双眼，丝巾呈现自然垂坠的面料纹理；画面右上角放置白色巴宝莉骑士品牌 logo，底部以大号白色无衬线字体标注 “BURBERRY”；光线为低调柔和的人像光，突出马匹毛发的细腻质感与丝巾的格纹细节，整体风格是高级艺术感的时尚品牌风，氛围神秘且契合品牌经典元素
      </Card>

      <Card title="生成图片" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-left.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-left.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        ![Description](https://cdn.bigmodel.cn/markdown/1768309771376image.png?attname=image.png)
      </Card>
    </CardGroup>
  </Tab>
</Tabs>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/code.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 调用示例 </div>

<Tabs>
  <Tab title="cURL">
    **调用示例**

    ```bash  theme={null}
    curl -X POST "https://open.bigmodel.cn/api/paas/v4/images/generations" \
        -H "Authorization: Bearer YOUR_API_KEY" \
        -H "Content-Type: application/json" \
        -d '{
            "model": "glm-image",
            "prompt": "一只可爱的小猫咪，坐在阳光明媚的窗台上，背景是蓝天白云",
            "size": "1280x1280"
        }'
    ```
  </Tab>

  <Tab title="Python">
    **安装 SDK**

    ```bash  theme={null}
    # 安装最新版本
    pip install zai-sdk
    # 或指定版本
    pip install zai-sdk==0.2.1
    ```

    **验证安装**

    ```python  theme={null}
    import zai
    print(zai.__version__)
    ```

    **调用示例**

    ```python  theme={null}
    from zai import ZhipuAiClient
    client = ZhipuAiClient(api_key="your-api-key")  # 请填写您自己的 APIKey
    response = client.images.generations(
        model="glm-image",  # 请填写您要调用的模型名称
        prompt="一只可爱的小猫咪，坐在阳光明媚的窗台上，背景是蓝天白云",
    )
    print(response.data[0].url)
    ```
  </Tab>

  <Tab title="Java">
    **安装 SDK**

    **Maven**

    ```xml  theme={null}
    <dependency>
        <groupId>ai.z.openapi</groupId>
        <artifactId>zai-sdk</artifactId>
        <version>0.3.2</version>
    </dependency>
    ```

    **Gradle (Groovy)**

    ```groovy  theme={null}
    implementation 'ai.z.openapi:zai-sdk:0.3.2'
    ```

    **调用示例**

    ```java  theme={null}
    import ai.z.openapi.ZhipuAiClient;
    import ai.z.openapi.core.Constants;
    import ai.z.openapi.service.image.CreateImageRequest;
    import ai.z.openapi.service.image.ImageResponse;

    public class GlmImageExample {
        public static void main(String[] args) {
            ZhipuAiClient client = ZhipuAiClient.builder().ofZHIPU().apiKey("YOUR_API_KEY").build();
            // Create image generation request
            CreateImageRequest request = CreateImageRequest.builder()
                .model("glm-image")
                .prompt("一只可爱的小猫咪，坐在阳光明媚的窗台上，背景是蓝天白云")
                .size("1280x1280")
                .build();
            ImageResponse response = client.images().createImage(request);
            System.out.println(response.getData());
        }
    }
    ```
  </Tab>
</Tabs>









> ## Documentation Index
> Fetch the complete documentation index at: https://docs.bigmodel.cn/llms.txt
> Use this file to discover all available pages before exploring further.

# GLM-Image

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/rectangle-list.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 概览 </div>

GLM-Image 是智谱新旗舰图像生成模型， 模型全程基于国产芯片完成训练，采用独创的「自回归+扩散解码器」混合架构，兼顾全局指令理解与局部细节刻画，克服了海报、PPT、科普图等知识密集型场景生成难题，是面向以 Nano Banana Pro 为代表的新一代「认知型生成」技术范式的一次重要探索。

<CardGroup cols={2}>
  <Card title="价格" icon={<svg style={{maskImage: "url(/resource/icon/coins.svg)", WebkitMaskImage: "url(/resource/icon/coins.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    0.1 元 / 次
  </Card>

  <Card title="输入模态" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-right.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-right.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    文本（最大输入1000字符）
  </Card>

  <Card title="输出模态" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-left.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-left.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    图像
  </Card>

  <Card title="多分辨率" icon={<svg style={{maskImage: "url(/resource/icon/images.svg)", WebkitMaskImage: "url(/resource/icon/images.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    支持 1:1、3:4、4:3、16:9 等
  </Card>
</CardGroup>

<Tip>
  **推荐常用尺寸：** 1280x1280 、 1568x1056 、 1056x1568 、 1472x1088 、 1088x1472 、 1728x960 、 960x1728。

  **自定义参数：** 长宽需在 512px-2048px 范围内，且长宽均需为32的整数倍。
</Tip>

<Info>
  请注意，GLM-Image 模型的输出是图片 URL，您需要通过 URL 下载图片。
</Info>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/stars.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 推荐场景 </div>

<AccordionGroup>
  <Accordion title="商业海报">
    能够生成构图完整、视觉层次清晰、整体设计感突出的节日海报与商业宣传图片，并支持文字内容的精准嵌入与稳定呈现，适用于品牌传播、市场推广等多种商业场景。
  </Accordion>

  <Accordion title="科普插画">
    更擅长绘制包含复杂逻辑关系、流程说明与文字注释的科普插画和原理示意图，能够在保证画面美观的同时，清晰、准确地传达知识结构与核心信息。
  </Accordion>

  <Accordion title="多格图画">
    在生成电商展示图、故事漫画等多格图画时，GLM-Image 可以有效保持整体画风与主体形象的一致性，同时显著提升多处文字生成的准确率，确保内容连贯、表达统一。
  </Accordion>

  <Accordion title="社交媒体图文">
    适用于制作封面设计与版式结构较为复杂的社交媒体图文内容，支持灵活排版与多样化表达，让创作过程更加高效，呈现效果更加丰富多元。
  </Accordion>
</AccordionGroup>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/gauge-high.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 使用资源 </div>

[体验中心](https://bigmodel.cn/trialcenter/modeltrial/image)：快速测试模型在业务场景上的效果<br />
[接口文档](/api-reference/%E6%A8%A1%E5%9E%8B-api/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90)：API 调用方式

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/arrow-up.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 详细介绍 </div>

<Steps>
  <Step title="架构创新：读懂指令，写对文字" titleSize="h3">
    **GLM-image是我们面向「认知型生成」技术范式的一次重要探索，** 这是首个开源的工业表现级离散自回归图像生成模型。

    GLM-Image 引入了「自回归+扩散解码器」混合架构，融合了 9B 的自回归模型与 7B 的 DiT 扩散解码器。前者利用其语言模型的底座优势，专注于提升对指令的语义理解和画面的全局构图；后者配合 Glyph Encoder 的文本编码器，专注于还原图像的高频细节和文字笔画，以此改善模型“提笔忘字”的现象。

    ![Description](https://cdn.bigmodel.cn/markdown/1768305506516image.png?attname=image.png)
    *general pipeline*

    ![Description](https://cdn.bigmodel.cn/markdown/1768305604344image.png?attname=image.png)
    *decoder formulation*
  </Step>

  <Step title="开源 SOTA：更擅长文字密集生成任务" stepNumber={2} titleSize="h3">
    基于上述架构创新，GLM-Image在文字渲染的权威榜单中达到开源 SOTA水平。

    ![Description](https://cdn.bigmodel.cn/markdown/1768308056990image.png?attname=image.png)

    * **CVTG-2K（复杂视觉文字生成）** 榜单核心考察模型在图像中同时生成多处文字的准确性。在多区域文字生成准确率上，GLM-Image 凭借 0.9116 的 Word Accuracy（文字准确率）成绩，位列开源模型前列。在NED（归一化编辑距离）指标上，GLM-Image 同样以 0.9557 胜出，表明其生成的文字与目标文字高度一致，错字、漏字情况更少。
    * **LongText-Bench（长文本渲染）** 榜单考察模型渲染长文本、多行文字的准确性，覆盖招牌、海报、PPT、对话框等8种文字密集场景，并分设中英双语测试，GLM-Image以英文0.9524、中文0.9788的成绩位列开源模型前列。
  </Step>

  <Step title="首个国产芯片训练出的 SOTA 多模态模型" stepNumber={3} titleSize="h3">
    GLM-Image 是我们对国产计算生态的一次深度探索与验证。从早期的数据预处理到最终的大规模预训练，模型构建的全流程均在昇腾Atlas 800T A2设备上完成。

    GLM-Image 是首个在国产芯片上完成全流程训练的SOTA多模态模型，验证了在国产全栈算力底座上训练高性能多模态生成模型的可行性。我们希望这一实践能为社区挖掘国产算力潜力提供有价值的参考。

    ![Description](https://cdn.bigmodel.cn/markdown/1768310696625image.png?attname=image.png)
  </Step>
</Steps>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/ballot.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 应用示例 </div>

<Tabs>
  <Tab title="科普插画">
    <CardGroup cols={2}>
      <Card title="Prompt" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-right.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-right.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        竖版手工剪贴簿风格的图像。顶部是一条亮红色粗糙撕裂边缘的纸质横幅，用半透明和纸胶带斜着固定，左上角夹着金色回形针，压着一小块写有「首发」的碎纸。横幅上用粗黑体手工剪报风写着主标题「GLM-Image 开源：国产芯片炼出图像生成 SOTA」，标题周围用黑色马克笔画着放射线和手绘画笔调色盘图标。
        背景是拼贴的AI生成图片碎片、芯片电路图纹理、水彩晕染和浅蓝色卡纸。左侧有一个带磨损金属边的数码相框，用透明胶带斜贴，相框内大字写着「自回归 + 扩散解码器」，副标题「9B 自回归理解指令 + 7B DiT 精绘细节」，背景是文字prompt气泡到精美图像的箭头连接图，边缘有手绘箭头标注「读懂指令」「写对文字」。
        右侧散落三张不同颜色的撕裂纸条便利贴，被和纸胶带交叉固定。配有芯片实物照片剪影加华为logo小贴纸、中文艺术字海报截图、多分辨率图像网格等插图。三个撕裂纸条标签带粗黑描边：「昇腾 A2 + 昇思 MindSpore：全程国产训练」「CVTG-2K & LongText-Bench：文字渲染开源第一」「384×384 到 2048×2048：任意比例原生支持」。旁边还有一条窄蓝色撕裂纸条写着「认知型生成：知识 + 推理新范式」，上面有马克笔波浪线和星星。
        底部是一整条深蓝色撕裂纸带，印着电路纹理，用和纸胶带固定。通栏大标题「从"画个图"到"懂你想要什么"的认知型生成引擎」
      </Card>

      <Card title="生成图片" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-left.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-left.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        ![Description](https://cdn.bigmodel.cn/markdown/176832067703920260113-235926.jpeg)
      </Card>
    </CardGroup>
  </Tab>

  <Tab title="高质量人像">
    <CardGroup cols={2}>
      <Card title="Prompt" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-right.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-right.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        哈苏胶片质感的画面中，一位长发美女置身于柔和的室内光影里，窗外的枝叶在微风中摇曳，将斑驳的树影投射到她的脸庞和肩头；薄纱轻轻垂落在背景，营造出朦胧唯美的氛围，轮廓光勾勒出她慵懒自然的姿态，凌乱的长发在风中轻轻飘起，发丝在阳光的照射下泛着微光；近景特写捕捉她深情凝望镜头的瞬间，清透细腻的肌肤在高曝光与高明暗的对比中展现丰富的质感，背景略微模糊，泛光与晕染交织出轻柔的梦幻效果，画面带有高噪点的胶片色彩与微妙的反射，整体细节生动，仿佛凝固在午后微风与光影交错的诗意瞬间。
      </Card>

      <Card title="生成图片" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-left.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-left.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        ![Description](https://cdn.bigmodel.cn/markdown/1768310904165image.png?attname=image.png)
      </Card>
    </CardGroup>
  </Tab>

  <Tab title="社交媒体图文">
    <CardGroup cols={2}>
      <Card title="Prompt" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-right.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-right.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        <br />

        冬季 OOTD 穿搭封面，复古拼贴风：主体是一位女生的主穿搭（浅蓝宽松毛衣 + 黄格衬衫内搭 + 酒红半裙 + 粉白花纹围巾 + 粉调手提包），周围拼贴 2-3 张同系列冬季搭配小图（如蓝羽绒服 + 黑阔腿裤、棕外套 + 藏青裤）；背景融合浅灰方格墙面 + 户外街景局部；添加大尺寸浅蓝艺术字 “OOTD”，手写风标注文字（如 “autumn/win”“work/date”），点缀星星、手绘箭头等小装饰，以及咖啡杯、播放键小图标；整体色调柔和温暖，元素错落排版，营造活泼的冬日穿搭参考感
      </Card>

      <Card title="生成图片" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-left.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-left.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        ![Description](https://cdn.bigmodel.cn/markdown/1768309855615image.png?attname=image.png)
      </Card>
    </CardGroup>
  </Tab>

  <Tab title="商业海报">
    <CardGroup cols={2}>
      <Card title="Prompt" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-right.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-right.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        <br />

        暗黑艺术感巴宝莉品牌宣传海报：整体采用低饱和深灰色暗调背景，配色以黑白（两匹马）+ 巴宝莉标志性红黑格纹（含白、浅棕线条）为主，文字与 logo 为白色；主体是两匹写实细腻质感的马（左侧纯白、右侧纯黑），头部均被巴宝莉经典红黑格纹丝巾蒙住双眼，丝巾呈现自然垂坠的面料纹理；画面右上角放置白色巴宝莉骑士品牌 logo，底部以大号白色无衬线字体标注 “BURBERRY”；光线为低调柔和的人像光，突出马匹毛发的细腻质感与丝巾的格纹细节，整体风格是高级艺术感的时尚品牌风，氛围神秘且契合品牌经典元素
      </Card>

      <Card title="生成图片" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-left.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-left.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
        ![Description](https://cdn.bigmodel.cn/markdown/1768309771376image.png?attname=image.png)
      </Card>
    </CardGroup>
  </Tab>
</Tabs>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/code.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 调用示例 </div>

<Tabs>
  <Tab title="cURL">
    **调用示例**

    ```bash  theme={null}
    curl -X POST "https://open.bigmodel.cn/api/paas/v4/images/generations" \
        -H "Authorization: Bearer YOUR_API_KEY" \
        -H "Content-Type: application/json" \
        -d '{
            "model": "glm-image",
            "prompt": "一只可爱的小猫咪，坐在阳光明媚的窗台上，背景是蓝天白云",
            "size": "1280x1280"
        }'
    ```
  </Tab>

  <Tab title="Python">
    **安装 SDK**

    ```bash  theme={null}
    # 安装最新版本
    pip install zai-sdk
    # 或指定版本
    pip install zai-sdk==0.2.1
    ```

    **验证安装**

    ```python  theme={null}
    import zai
    print(zai.__version__)
    ```

    **调用示例**

    ```python  theme={null}
    from zai import ZhipuAiClient
    client = ZhipuAiClient(api_key="your-api-key")  # 请填写您自己的 APIKey
    response = client.images.generations(
        model="glm-image",  # 请填写您要调用的模型名称
        prompt="一只可爱的小猫咪，坐在阳光明媚的窗台上，背景是蓝天白云",
    )
    print(response.data[0].url)
    ```
  </Tab>

  <Tab title="Java">
    **安装 SDK**

    **Maven**

    ```xml  theme={null}
    <dependency>
        <groupId>ai.z.openapi</groupId>
        <artifactId>zai-sdk</artifactId>
        <version>0.3.2</version>
    </dependency>
    ```

    **Gradle (Groovy)**

    ```groovy  theme={null}
    implementation 'ai.z.openapi:zai-sdk:0.3.2'
    ```

    **调用示例**

    ```java  theme={null}
    import ai.z.openapi.ZhipuAiClient;
    import ai.z.openapi.core.Constants;
    import ai.z.openapi.service.image.CreateImageRequest;
    import ai.z.openapi.service.image.ImageResponse;

    public class GlmImageExample {
        public static void main(String[] args) {
            ZhipuAiClient client = ZhipuAiClient.builder().ofZHIPU().apiKey("YOUR_API_KEY").build();
            // Create image generation request
            CreateImageRequest request = CreateImageRequest.builder()
                .model("glm-image")
                .prompt("一只可爱的小猫咪，坐在阳光明媚的窗台上，背景是蓝天白云")
                .size("1280x1280")
                .build();
            ImageResponse response = client.images().createImage(request);
            System.out.println(response.getData());
        }
    }
    ```
  </Tab>
</Tabs>










> ## Documentation Index
> Fetch the complete documentation index at: https://docs.bigmodel.cn/llms.txt
> Use this file to discover all available pages before exploring further.

# GLM-4-Voice

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/rectangle-list.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 概览 </div>

GLM-4-Voice 是智谱推出的首个端到端语音模型。它能够直接理解和生成中英文语音，实现实时语音对话，并可根据用户指令灵活调整语音的情感、语调、语速和方言等特性，使语音交互更加自然生动。

<CardGroup cols={3}>
  <Card title="价格" icon={<svg style={{maskImage: "url(/resource/icon/coins.svg)", WebkitMaskImage: "url(/resource/icon/coins.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    80 元 / 百万 Tokens
  </Card>

  <Card title="输入模态" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-right.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-right.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    音频、文本
  </Card>

  <Card title="输出模态" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-left.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-left.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    音频
  </Card>

  <Card title="上下文窗口" icon={<svg style={{maskImage: "url(/resource/icon/arrow-down-arrow-up.svg)", WebkitMaskImage: "url(/resource/icon/arrow-down-arrow-up.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    8K
  </Card>

  <Card title="最大输出 Tokens" icon={<svg style={{maskImage: "url(/resource/icon/maximize.svg)", WebkitMaskImage: "url(/resource/icon/maximize.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    4K
  </Card>
</CardGroup>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/stars.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 推荐场景 </div>

<AccordionGroup>
  <Accordion title="角色陪伴" defaultOpen>
    AI 通过虚拟角色（如游戏角色、虚拟偶像）与用户进行情感化对话，虚拟角色可以设定为特定性格、背景和声音，实现全天候陪伴。
  </Accordion>

  <Accordion title="智能导游" defaultOpen>
    AI 导游与用户进行实时语音交互，为用户提供详细的历史背景、文化意义和建筑特点，通过语音描述帮助用户规划游览路线，解答用户关于景点的疑问。
  </Accordion>

  <Accordion title="英语学习" defaultOpen>
    AI 英语老师通过模拟真实场景（如点餐、问路）与用户进行对话练习，解答用户关于语法规则的疑问，实时纠正用户发音、学习日常表达和语法知识，并提供改进建议。
  </Accordion>

  <Accordion title="在线教育" defaultOpen>
    AI 辅导老师与学生通过详细讲解课程内容，为学生提供课程讲解、作业辅导和学习建议，涵盖多个学科（如数学、历史、科学），解答学生在作业中遇到的问题，通过多轮对话帮助学生理解难点。
  </Accordion>
</AccordionGroup>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/gauge-high.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 使用资源 </div>

[接口文档](/api-reference/%E6%A8%A1%E5%9E%8B-api/%E5%AF%B9%E8%AF%9D%E8%A1%A5%E5%85%A8)：API 调用方式

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/arrow-up.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 详细介绍 </div>

<Steps>
  <Step icon={<svg style={{maskImage: "url(/resource/icon/star.svg)", WebkitMaskImage: "url(/resource/icon/star.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />}>
    凭借其实时语音对话功能，GLM-4-Voice 为用户提供高效流畅的沟通体验。GLM-4-Voice具备情感表达、方言生成和语速调节的能力，同时支持中英文双语。它的应用场景广泛，覆盖虚拟角色互动、智慧教育、智能旅游、儿童陪伴等多个领域。通过灵活的语音输入和输出能力，GLM-4-Voice 能够为用户提供高效且个性化的服务体验。

    在企业应用方面，GLM-4-Voice 可针对不同垂直行业定制专业的场景解决方案，帮助开发者以较低成本快速适应和融入大模型时代。
  </Step>
</Steps>

# <svg style={{maskImage: "url(/resource/icon/code.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} />   调用示例

<Tabs>
  <Tab title="Python">
    **安装 SDK**

    ```bash  theme={null}
    # 安装最新版本
    pip install zai-sdk
    # 或指定版本
    pip install zai-sdk==0.2.2
    ```

    **验证安装**

    ```python  theme={null}
    import zai
    print(zai.__version__)
    ```

    **调用示例**

    ```python  theme={null}
    import wave
    import base64
    from zai import ZhipuAiClient

    def save_audio_as_wav(audio_data, filepath):
        """保存音频数据为 WAV 文件（模型返回的语音用）"""
        with wave.open(filepath, 'wb') as wav_file:
            wav_file.setnchannels(1)
            wav_file.setsampwidth(2)
            wav_file.setframerate(44100)
            wav_file.writeframes(audio_data)
        print(f"Audio saved to {filepath}")

    def get_base64_from_wav(wav_path):
        """将 WAV 文件转为 Base64 编码字符串"""
        with open(wav_path, "rb") as f:
            audio_bytes = f.read()
        return base64.b64encode(audio_bytes).decode("utf-8")

    client = ZhipuAiClient(api_key="your_api_key")  # 请填写您自己的 APIKey

    input_wav_path = "your_voice.wav"  # 你的 WAV 文件路径
    base64_voice = get_base64_from_wav(input_wav_path)

    response = client.chat.completions.create(
        model="glm-4-voice",
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "你好，这是我的语音输入测试，请慢速复述一遍"
                    },
                    {
                        "type": "input_audio",
                        "input_audio": {
                            "data": base64_voice,
                            "format": "wav"
                        }
                    }
                ]
            }
        ],
        stream=False
    )

    print(response.choices[0].message.content)

    # 解析并保存模型返回的语音
    try:
        audio_data = response.choices[0].message.audio['data']
        decoded_data = base64.b64decode(audio_data)
        save_audio_as_wav(decoded_data, "output.wav")
    except Exception as e:
        print("处理音频失败：", e)
    ```
  </Tab>

  <Tab title="Java">
    **安装 SDK**

    **Maven**

    ```xml  theme={null}
    <dependency>
        <groupId>ai.z.openapi</groupId>
        <artifactId>zai-sdk</artifactId>
        <version>0.3.3</version>
    </dependency>
    ```

    **Gradle (Groovy)**

    ```groovy  theme={null}
    implementation 'ai.z.openapi:zai-sdk:0.3.3'
    ```

    **调用示例**

    ```java  theme={null}
      import ai.z.openapi.ZhipuAiClient;
      import ai.z.openapi.service.model.ChatCompletionCreateParams;
      import ai.z.openapi.service.model.ChatCompletionResponse;
      import ai.z.openapi.service.model.ChatMessage;
      import ai.z.openapi.service.model.ChatMessageRole;
      import ai.z.openapi.service.model.InputAudio;
      import ai.z.openapi.service.model.MessageContent;

      import java.io.File;
      import java.io.IOException;
      import java.nio.file.Files;
      import java.util.Arrays;
      import java.util.Base64;
      import java.util.Collections;

      public class GLM4VoiceExample {
          public static void main(String[] args) throws IOException {
              ZhipuAiClient client = ZhipuAiClient.builder().ofZHIPU().apiKey("API_KEY").build();
              File audioFile = new File("your_path.asr.wav");
              byte[] audioBytes = Files.readAllBytes(audioFile.toPath());
              String base64 = Base64.getEncoder().encodeToString(audioBytes);
              ChatCompletionCreateParams request = ChatCompletionCreateParams.builder().model("glm-4-voice")
                  .messages(Collections.singletonList(ChatMessage.builder()
                  .role(ChatMessageRole.USER.value())
                  .content(
                      Arrays.asList(MessageContent.builder().type("text").text("你好，这是我的语音输入测试").build(),
                      MessageContent.builder().type("input_audio").inputAudio(InputAudio.builder()
                          .data(base64).format("wav").build()).build())).build())).build();
              ChatCompletionResponse response = client.chat().createChatCompletion(request);
              if (response.isSuccess()) {
                  Object reply = response.getData().getChoices().get(0).getMessage().getContent();
                  System.out.println(reply);
              } else {
                  System.err.println("错误: " + response.getMsg());
              }
          }
    }
    ```
  </Tab>

  <Tab title="旧版 Python">
    ```python  theme={null}
    import zhipuai
    import wave
    import base64

    def get_base64_from_wav(wav_path):
        """将 WAV 文件转为 Base64 编码字符串"""
        with open(wav_path, "rb") as f:
            audio_bytes = f.read()
        return base64.b64encode(audio_bytes).decode("utf-8")

    zhipuai.api_key = "your_api_key"  # 请填写您自己的 APIKey

    input_wav_path = "your_voice.wav"
    base64_voice = get_base64_from_wav(input_wav_path)

    response = zhipuai.model_api.invoke(
        model="glm-4-voice",
        prompt="你好，这是我的语音输入测试",
        audio_data=base64_voice,
        audio_format="wav"
    )

    print(response)
    ```
  </Tab>

  <Tab title="输出示例">
    ```json  theme={null}
    {
        "id": "20250605132035222ead927d794645",
        "object": "chat.completion",
        "created": 1749187238,
        "model": "glm-4-voice",
        "choices": [
            {
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": "你好！我听到了你的语音输入。有什么我可以帮助你的吗？",
                    "audio": {
                        "data": "707hTvovBW8zH3FPxH/1sCvgTXB/kJPQtJCqMIEgcCBUcDRQBZ...",
                        "expires_at": 1749187238,
                        "id": "f8d4bf4b-a376-48e6-8c81-54bb6a9a31d0"
                    }
                },
                "finish_reason": "stop"
            }
        ],
        "usage": {
            "prompt_tokens": 107,
            "completion_tokens": 340,
            "total_tokens": 447
        },
        "request_id": "20250605132035222ead927d794645"
    }
    ```
  </Tab>
</Tabs>

## <div className="flex items-center"> <svg style={{maskImage: "url(/resource/icon/square-user.svg)", maskRepeat: "no-repeat", maskPosition: "center center",}} className={"h-6 w-6 bg-primary dark:bg-primary-light !m-0 shrink-0"} /> 用户并发权益 </div>

API 调用会受到速率限制，当前我们限制的维度是请求并发数量（在途请求任务数量）。不同等级的用户并发保障如下。

| V0 | V1 | V2 | V3 |
| :- | :- | :- | :- |
| 5  | 10 | 15 | 20 |

